# Source Tree & Module Organization

**Project:** AI-Driven Market-Informed Character IP Design & Demand Forecasting
**Version:** 1.0
**Last Updated:** 2025-11-06
**Status:** Obj 1-3 Complete, Obj 4 Pending

---

## Project Structure Overview

```
FYP-RoleMarket/
â”œâ”€â”€ obj1_nlp_prompt/           # Objective 1: Trend Analysis & Prompt Generation
â”œâ”€â”€ obj2_midjourney_api/       # Objective 2: Image Generation (Google Gemini)
â”œâ”€â”€ obj3_lstm_forecast/        # Objective 3: Sales Forecasting (Transformer)
â”œâ”€â”€ obj4_web_app/              # Objective 4: Streamlit Web Application (â³ Pending)
â”œâ”€â”€ data/                      # Data Storage (cache, images, datasets)
â”œâ”€â”€ models/                    # Trained Model Weights
â”œâ”€â”€ config/                    # Configuration Files
â”œâ”€â”€ docs/                      # Documentation
â”œâ”€â”€ tests/                     # Test Scripts
â”œâ”€â”€ scripts/                   # Utility Scripts
â”œâ”€â”€ reports/                   # Analysis Reports
â”œâ”€â”€ hf-spaces-deploy/          # Hugging Face Spaces Deployment (Optional)
â”œâ”€â”€ .bmad-core/                # BMAD Framework Files (PM/Dev/Architect agents)
â”œâ”€â”€ requirements.txt           # Python Dependencies
â”œâ”€â”€ docker-compose.yml         # Docker Setup
â””â”€â”€ README.md                  # Project Overview
```

---

## Module Breakdown

### 1. Objective 1: Trend Analysis & Prompt Generation (`obj1_nlp_prompt/`)

**Purpose:** æå– Google Trends æ•¸æ“šï¼Œåˆ†ææ–‡åŒ–è¶¨å‹¢ï¼Œç”Ÿæˆ AI åœ–ç‰‡ Prompts

**Directory Structure:**
```
obj1_nlp_prompt/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ enhanced_trends_pipeline.py      # â­ ä¸»æµç¨‹ - å®Œæ•´ pipeline å…¥å£
â”œâ”€â”€ category_trends_extractor.py     # Google Trends æå–
â”œâ”€â”€ cultural_trend_adapter.py        # æ–‡åŒ–è¶¨å‹¢è½‰åŒ–ï¼ˆMeme, Holiday, Design Styleï¼‰
â”œâ”€â”€ prompt_generator.py              # LLM-based Prompt ç”Ÿæˆ
â”œâ”€â”€ keyword_extractor.py             # TF-IDF é—œéµå­—æå–
â”œâ”€â”€ keyword_optimizer.py             # é—œéµå­—éæ¿¾å„ªåŒ–
â”œâ”€â”€ meme_analyzer.py                 # Meme è¶¨å‹¢åˆ†æ
â”œâ”€â”€ seasonal_trends_extractor.py     # å­£ç¯€è¶¨å‹¢æå–
â”œâ”€â”€ demo_category_interactive.py     # Interactive Demo
â””â”€â”€ templates/
    â””â”€â”€ prompt_template.txt          # Prompt æ¨¡æ¿
```

**Key Files:**

| File | Purpose | Status | Dependencies |
|------|---------|--------|--------------|
| `enhanced_trends_pipeline.py` | **ä¸»è¦å…¥å£é»** - æ•´åˆæ‰€æœ‰æ¨¡çµ„ | âœ… å®Œæˆ | æ‰€æœ‰å…¶ä»–æ¨¡çµ„ |
| `category_trends_extractor.py` | ç¤¾äº¤åª’é«”ç¨®å­è©æå–è¶¨å‹¢ | âœ… å®Œæˆ | pytrends |
| `cultural_trend_adapter.py` | å°‡è¶¨å‹¢è½‰åŒ–ç‚ºè§’è‰²è¨­è¨ˆå…ƒç´  | âœ… å®Œæˆ | - |
| `prompt_generator.py` | GPT API èª¿ç”¨ç”Ÿæˆ Prompt | âœ… å®Œæˆ | OpenAI API |

**Integration Points:**
- **Input:** è¶¨å‹¢é—œéµå­—ï¼ˆå¦‚ "æ˜¥ç¯€, ç´…è‰², å–œæ…¶"ï¼‰
- **Output:** å®Œæ•´ AI åœ–ç‰‡ Promptï¼ˆä¾› Obj 2 ä½¿ç”¨ï¼‰
- **External APIs:** Google Trends (pytrends), GPT_API_free

**Usage Example:**
```python
from obj1_nlp_prompt.enhanced_trends_pipeline import EnhancedTrendsPipeline

pipeline = EnhancedTrendsPipeline(region='HK', lang='zh-TW')
prompt = pipeline.generate_prompt(
    character_name="Lulu Pig",
    character_desc="å¯æ„›ç²‰ç´…è±¬",
    trend_keywords=["æ˜¥ç¯€", "ç´…è‰²", "å–œæ…¶"]
)
```

---

### 2. Objective 2: Image Generation (`obj2_midjourney_api/`)

**Purpose:** ä½¿ç”¨ Google Gemini API ç”Ÿæˆè§’è‰²è¨­è¨ˆåœ–ï¼Œä¸¦ç”¨ CLIP é©—è­‰ä¸€è‡´æ€§

**Directory Structure:**
```
obj2_midjourney_api/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ google_gemini_client.py          # â­ Google Gemini API Client
â”œâ”€â”€ gemini_image_client.py           # Alternative Gemini Client
â”œâ”€â”€ character_focused_validator.py   # â­ CLIP ç›¸ä¼¼åº¦é©—è­‰
â”œâ”€â”€ clip_validator.py                # CLIP Validator (Deprecated)
â”œâ”€â”€ batch_generate_async.py          # æ‰¹é‡ç”Ÿæˆï¼ˆéåŒæ­¥ï¼‰
â”œâ”€â”€ generate_scene_variations.py     # å ´æ™¯è®ŠåŒ–ç”Ÿæˆ
â”œâ”€â”€ analyze_reference_images.py      # åƒè€ƒåœ–åˆ†æ
â”œâ”€â”€ ttapi_client.py                  # âš ï¸ Legacy - åŸ TTAPI Midjourney Client
â”œâ”€â”€ test_*.py                        # æ¸¬è©¦è…³æœ¬ï¼ˆå¤šå€‹ï¼‰
â””â”€â”€ validators/
    â””â”€â”€ ...                          # é©—è­‰å™¨æ¨¡çµ„
```

**Key Files:**

| File | Purpose | Status | Notes |
|------|---------|--------|-------|
| `google_gemini_client.py` | **ä¸»è¦ç”Ÿæˆ Client** | âœ… å®Œæˆ | å–ä»£ TTAPI Midjourney |
| `character_focused_validator.py` | **CLIP é©—è­‰** | âœ… å®Œæˆ | ç›¸ä¼¼åº¦ threshold â‰¥ 0.80 |
| `ttapi_client.py` | TTAPI Midjourney Client | âš ï¸ Deprecated | å·²æ£„ç”¨ï¼Œä¿ç•™ä¾›åƒè€ƒ |

**Integration Points:**
- **Input:** Promptï¼ˆä¾†è‡ª Obj 1ï¼‰ï¼ŒReference Image Path
- **Output:** ç”Ÿæˆåœ–ç‰‡ + CLIP ç›¸ä¼¼åº¦åˆ†æ•¸
- **External APIs:** Google Gemini 2.5 Flash Image
- **Models:** CLIP ViT-Large/14 (local inference)

**Usage Example:**
```python
from obj2_midjourney_api.google_gemini_client import GoogleGeminiImageClient
from obj2_midjourney_api.character_focused_validator import CharacterValidator

# ç”Ÿæˆåœ–ç‰‡
client = GoogleGeminiImageClient()
result = client.generate(
    prompt="Lulu Pig celebrating Christmas",
    reference_image_path="data/reference_images/lulu_pig_ref_1.jpg"
)

# é©—è­‰ç›¸ä¼¼åº¦
validator = CharacterValidator()
similarity = validator.compute_clip_similarity(
    result['image'],
    "data/reference_images/lulu_pig_ref_1.jpg"
)
```

**Technical Debt:**
- âš ï¸ å¤šå€‹æ¸¬è©¦è…³æœ¬æ•£è½ï¼ˆ`test_*.py`ï¼‰ï¼Œç¼ºå°‘çµ±ä¸€æ¸¬è©¦æ¡†æ¶
- âš ï¸ `ttapi_client.py` å·²æ£„ç”¨ä½†æœªç§»é™¤ï¼ˆä¿ç•™ä¾›æ­·å²åƒè€ƒï¼‰

---

### 3. Objective 3: Sales Forecasting (`obj3_lstm_forecast/`)

**Purpose:** åŸºæ–¼è¶¨å‹¢æ•¸æ“šå’Œ CLIP embeddings é æ¸¬éŠ·é‡

**Directory Structure:**
```
obj3_lstm_forecast/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ hybrid_transformer_model.py      # â­ æœ€çµ‚ Transformer æ¶æ§‹
â”œâ”€â”€ kaggle_train_lulu_exp11v2.py     # â­ æœ€çµ‚è¨“ç·´è…³æœ¬ï¼ˆRÂ² = 0.6788ï¼‰
â”œâ”€â”€ hybrid_lstm_model.py             # Legacy LSTM ç‰ˆæœ¬ï¼ˆå·²æ·˜æ±°ï¼‰
â”œâ”€â”€ kaggle_train_lulu_*.py           # å¯¦é©—è…³æœ¬ï¼ˆExp 10-14ï¼‰
â”œâ”€â”€ generate_lulu_production_data_v*.py  # æ•¸æ“šç”Ÿæˆè…³æœ¬
â”œâ”€â”€ train.py                         # æœ¬åœ°è¨“ç·´è…³æœ¬
â”œâ”€â”€ test_local_*.py                  # æœ¬åœ°æ¸¬è©¦è…³æœ¬
â””â”€â”€ data/
    â””â”€â”€ ...                          # è¨“ç·´æ•¸æ“šï¼ˆCSVï¼‰
```

**Key Files:**

| File | Purpose | Status | Notes |
|------|---------|--------|-------|
| `hybrid_transformer_model.py` | **æœ€çµ‚æ¨¡å‹æ¶æ§‹** | âœ… ç”Ÿç”¢ | D_MODEL=64, NUM_LAYERS=2 |
| `kaggle_train_lulu_exp11v2.py` | **æœ€çµ‚è¨“ç·´è…³æœ¬** | âœ… ç”Ÿç”¢ | RÂ²=0.6788, MAE=327.26 |
| `hybrid_lstm_model.py` | Legacy LSTM ç‰ˆæœ¬ | âš ï¸ Deprecated | å¯¦é©—çµæœè¼ƒå·®ï¼Œå·²æ·˜æ±° |
| `kaggle_train_lulu_exp12*.py` | Ensemble å¯¦é©— | âš ï¸ Overfitting | æ•¸æ“šæ´©æ¼å•é¡Œï¼Œä¸æ¡ç”¨ |

**Model Architecture (Exp #11v2):**
```python
class HybridTransformer(nn.Module):
    """
    Input:
        - Time-series: (batch, 4, 1) - éå» 4 å­£åº¦ Google Trends
        - Static: (batch, 772) - CLIP 768-dim + Product Type 4-dim

    Architecture:
        1. Time-series â†’ Embedding â†’ Positional Encoding â†’ Transformer Encoder
        2. Static â†’ FC Layers
        3. Fusion â†’ Output (é æ¸¬éŠ·é‡)

    Hyperparameters:
        - D_MODEL = 64
        - NUM_LAYERS = 2
        - NHEAD = 8
        - DROPOUT = 0.1
        - LR = 0.0001
        - EPOCHS = 400 (early stop at 155)
    """
```

**Integration Points:**
- **Input:**
  - Time-series: Google Trends æ­·å²ï¼ˆ4 å­£åº¦ï¼‰
  - Static: CLIP embeddings (768-dim) + Season encoding (4-dim)
- **Output:** é æ¸¬éŠ·é‡ï¼ˆæ•¸å€¼ï¼‰
- **Model Weights:** `models/transformer_lulu/best_model.pth`

**Usage Example:**
```python
from obj3_lstm_forecast.hybrid_transformer_model import HybridTransformer
import torch

# è¼‰å…¥æ¨¡å‹
model = HybridTransformer(d_model=64, num_layers=2, nhead=8)
model.load_state_dict(torch.load("models/transformer_lulu/best_model.pth"))
model.eval()

# é æ¸¬
ts = torch.FloatTensor(trends_history).unsqueeze(0)  # (1, 4, 1)
static = torch.FloatTensor(clip_embedding + season_encoding).unsqueeze(0)  # (1, 772)

with torch.no_grad():
    prediction = model(ts, static)
```

**Technical Debt:**
- âš ï¸ 14+ å€‹å¯¦é©—è…³æœ¬ï¼ˆ`kaggle_train_lulu_exp*.py`ï¼‰æœªæ¸…ç†
- âš ï¸ æ•¸æ“šç”Ÿæˆè…³æœ¬ç‰ˆæœ¬éå¤šï¼ˆv1, v2, v2.5, v3ï¼‰
- âš ï¸ æ¨¡å‹æ¬Šé‡åƒ…å„²å­˜æ–¼ localï¼Œæœªä¸Šå‚³è‡³ Hugging Face Hub

---

### 4. Objective 4: Web Application (`obj4_web_app/`) â³ Pending

**Purpose:** Streamlit Web UI æ•´åˆ Obj 1-3

**Planned Structure:**
```
obj4_web_app/
â”œâ”€â”€ app.py                          # Streamlit ä¸»å…¥å£
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_ğŸ¨_è¨­è¨ˆç”Ÿæˆ.py            # Page 1: Obj 1 + Obj 2
â”‚   â””â”€â”€ 2_ğŸ“Š_éŠ·é‡é æ¸¬.py            # Page 2: Obj 3
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trends_api.py               # Obj 1 Wrapper
â”‚   â”œâ”€â”€ design_generator.py         # Obj 2 Wrapper
â”‚   â”œâ”€â”€ forecast_predictor.py       # Obj 3 Wrapper
â”‚   â””â”€â”€ ui_helpers.py               # å…±ç”¨ UI å‡½æ•¸
â”œâ”€â”€ config.py                       # App é…ç½®
â””â”€â”€ README.md                       # ä½¿ç”¨èªªæ˜
```

**Status:** â³ å¾…é–‹ç™¼ï¼ˆå·²è¦åŠƒæ–¼ Epic 4ï¼‰

---

### 5. Data Directory (`data/`)

**Purpose:** æ‰€æœ‰æ•¸æ“šå„²å­˜ï¼ˆå¿«å–ã€åœ–ç‰‡ã€æ•¸æ“šé›†ï¼‰

**Structure:**
```
data/
â”œâ”€â”€ cache/                          # API å¿«å–
â”œâ”€â”€ reference_images/               # åƒè€ƒåœ–ç‰‡ï¼ˆè§’è‰²ä¸€è‡´æ€§ï¼‰
â”‚   â”œâ”€â”€ lulu_pig_ref_1.jpg
â”‚   â”œâ”€â”€ lulu_pig_ref_2.jpg
â”‚   â””â”€â”€ lulu_pig_ref_3.jpg
â”œâ”€â”€ generated_images/               # ç”Ÿæˆçš„è¨­è¨ˆåœ–
â”œâ”€â”€ clip_embeddings/                # CLIP embeddings å¿«å–
â”œâ”€â”€ prompts/                        # ç”Ÿæˆçš„ Prompts
â”œâ”€â”€ prompts_enhanced/               # å„ªåŒ–å¾Œçš„ Prompts
â”œâ”€â”€ trends/                         # Google Trends æ•¸æ“š
â”œâ”€â”€ trends_seasonal/                # å­£ç¯€è¶¨å‹¢æ•¸æ“š
â”œâ”€â”€ production_sales/               # ç”Ÿç”¢æ•¸æ“šé›†ï¼ˆæœ€çµ‚ç‰ˆæœ¬ï¼‰
â”œâ”€â”€ lulu_production_sales*/         # æ•¸æ“šé›†ç‰ˆæœ¬ï¼ˆv1, v2, v2.5, v3, augmented, enhancedï¼‰
â”œâ”€â”€ simulated_sales/                # æ¨¡æ“¬éŠ·å”®æ•¸æ“š
â””â”€â”€ results/                        # å¯¦é©—çµæœ
```

**Key Directories:**

| Directory | Purpose | Size | Notes |
|-----------|---------|------|-------|
| `reference_images/` | Reference Images | ~10MB | 3 å¼µ Lulu Pig åƒè€ƒåœ– |
| `generated_images/` | ç”Ÿæˆè¨­è¨ˆåœ– | ~100MB+ | æ¸¬è©¦éšæ®µç”Ÿæˆåœ–ç‰‡ |
| `clip_embeddings/` | CLIP Embeddings | ~50MB | 768-dim vectors (*.npy) |
| `lulu_production_sales*/` | è¨“ç·´æ•¸æ“šé›† | ~5MB | å¤šå€‹ç‰ˆæœ¬ï¼ˆæœ€çµ‚: production_salesï¼‰ |

**Technical Debt:**
- âš ï¸ æ•¸æ“šé›†ç‰ˆæœ¬éå¤šï¼ˆ7+ å€‹ç‰ˆæœ¬ï¼‰ï¼Œç¼ºå°‘ç‰ˆæœ¬ç®¡ç†ç­–ç•¥
- âš ï¸ ç”Ÿæˆåœ–ç‰‡æœªåˆ†é¡æ•´ç†ï¼ˆå»ºè­°æŒ‰ theme/date åˆ†é¡ï¼‰

---

### 6. Models Directory (`models/`)

**Purpose:** è¨“ç·´å¥½çš„æ¨¡å‹æ¬Šé‡

**Structure:**
```
models/
â”œâ”€â”€ transformer_lulu/               # â­ æœ€çµ‚ç”Ÿç”¢æ¨¡å‹ï¼ˆExp #11v2ï¼‰
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”œâ”€â”€ training_results.json
â”‚   â””â”€â”€ training_curve.png
â”œâ”€â”€ transformer_production/         # ç”Ÿç”¢ç´šæ¨¡å‹ï¼ˆå‚™ä»½ï¼‰
â”œâ”€â”€ ensemble_lulu/                  # Ensemble å¯¦é©—ï¼ˆæœªæ¡ç”¨ï¼‰
â”œâ”€â”€ lstm/                           # Legacy LSTM æ¨¡å‹ï¼ˆå·²æ·˜æ±°ï¼‰
â”œâ”€â”€ exp7_deeper_model/              # å¯¦é©— 7: æ›´æ·±æ¨¡å‹
â”œâ”€â”€ exp8_hyperparam_search/         # å¯¦é©— 8: è¶…åƒæ•¸æœç´¢
â”œâ”€â”€ test_original/                  # æœ¬åœ°æ¸¬è©¦æ¨¡å‹
â””â”€â”€ test_v2_5/                      # æœ¬åœ°æ¸¬è©¦æ¨¡å‹ v2.5
```

**Production Model:**
- **Location:** `models/transformer_lulu/best_model.pth`
- **Architecture:** HybridTransformer (D_MODEL=64, NUM_LAYERS=2)
- **Performance:** RÂ²=0.6788, MAE=327.26
- **Size:** ~10MB

**Technical Debt:**
- âš ï¸ å¯¦é©—æ¨¡å‹æœªæ¸…ç†ï¼ˆ7+ å€‹ç›®éŒ„ï¼‰
- âš ï¸ æ¨¡å‹æ¬Šé‡æœªç‰ˆæœ¬æ§åˆ¶ï¼ˆGit LFS or Hugging Face Hubï¼‰

---

### 7. Configuration (`config/`)

**Purpose:** API keys å’Œé…ç½®æ–‡ä»¶

**Structure:**
```
config/
â”œâ”€â”€ reference_images.py             # Reference Image è·¯å¾‘é…ç½®
â””â”€â”€ seasonal_timeframes.json        # å­£ç¯€æ™‚é–“æ¡†æ¶é…ç½®
```

**Environment Variables (`.env`):**
```bash
GOOGLE_API_KEY=<Google AI Studio API Key>
GPT_API_TOKEN=<GPT_API_free Token>
```

**Security Note:**
- âš ï¸ `.env` æª”æ¡ˆæ‡‰åŠ å…¥ `.gitignore`ï¼ˆå·²è™•ç†ï¼‰
- âš ï¸ æä¾› `.env.example` ä¾›åƒè€ƒ

---

### 8. Documentation (`docs/`)

**Purpose:** å°ˆæ¡ˆæ–‡æª”

**Structure:**
```
docs/
â”œâ”€â”€ prd.md                          # Product Requirements Document
â”œâ”€â”€ implementation-roadmap.md       # å¯¦æ–½è·¯ç·šåœ–
â”œâ”€â”€ experiment-log-lulu-transformer.md  # Obj 3 å¯¦é©—è¨˜éŒ„
â”œâ”€â”€ phase-a-completion-report.md    # Phase A å®Œæˆå ±å‘Š
â”œâ”€â”€ strategy-improvements-v1.2.md   # ç­–ç•¥æ”¹é€²è¨˜éŒ„
â”œâ”€â”€ epic-4-web-integration.md       # Obj 4 Epic
â”œâ”€â”€ architecture/                   # æ¶æ§‹æ–‡æª”ï¼ˆæœ¬ç›®éŒ„ï¼‰
â”‚   â”œâ”€â”€ tech-stack.md
â”‚   â”œâ”€â”€ source-tree.md
â”‚   â””â”€â”€ coding-standards.md
â””â”€â”€ stories/                        # User Stories
    â”œâ”€â”€ story-4.1-*.md
    â”œâ”€â”€ story-4.2-*.md
    â””â”€â”€ story-4.3-*.md
```

---

### 9. Testing (`tests/`)

**Purpose:** æ¸¬è©¦è…³æœ¬

**Structure:**
```
tests/
â”œâ”€â”€ test_character_focused_validation.py
â”œâ”€â”€ test_complete_e2e_detailed.py
â”œâ”€â”€ test_full_pipeline.py
â””â”€â”€ ...
```

**Status:** âš ï¸ æ¸¬è©¦è¦†è“‹ç‡ä½ï¼ˆ< 20%ï¼‰ï¼Œå¾…æ”¹é€²

---

### 10. Scripts (`scripts/`)

**Purpose:** å·¥å…·è…³æœ¬

**Status:** âš ï¸ ç›®å‰ç‚ºç©ºï¼Œå¾…è£œå……éƒ¨ç½²/æ¸…ç†è…³æœ¬

---

## Key Integration Points

### Cross-Module Data Flow

```
[User Input: è¶¨å‹¢é—œéµå­—]
        â†“
[Obj 1: enhanced_trends_pipeline.py]
        â†“ (Prompt)
[Obj 2: google_gemini_client.py]
        â†“ (Generated Image)
[Obj 2: character_focused_validator.py]
        â†“ (CLIP Embedding)
[Obj 3: hybrid_transformer_model.py]
        â†“ (Sales Prediction)
[Output: é æ¸¬éŠ·é‡]
```

### File Dependencies

**Obj 1 â†’ Obj 2:**
- Output: Prompt (string)
- Format: è©³ç´°è¨­è¨ˆæè¿°ï¼ˆ150-200 wordsï¼‰

**Obj 2 â†’ Obj 3:**
- Output: CLIP Embedding (768-dim numpy array)
- Format: `.npy` file or in-memory array

**Obj 3 â†’ Web UI:**
- Output: Prediction (float)
- Format: JSON or dict `{'predicted_sales': float, 'confidence': float}`

---

## Navigation Guide for AI Agents

### Quick Reference: "Where do I find...?"

| Task | Location |
|------|----------|
| **è¶¨å‹¢åˆ†æå…¥å£** | `obj1_nlp_prompt/enhanced_trends_pipeline.py` |
| **åœ–ç‰‡ç”Ÿæˆå…¥å£** | `obj2_midjourney_api/google_gemini_client.py` |
| **CLIP é©—è­‰** | `obj2_midjourney_api/character_focused_validator.py` |
| **é æ¸¬æ¨¡å‹** | `obj3_lstm_forecast/hybrid_transformer_model.py` |
| **è¨“ç·´è…³æœ¬ï¼ˆæœ€çµ‚ï¼‰** | `obj3_lstm_forecast/kaggle_train_lulu_exp11v2.py` |
| **æ¨¡å‹æ¬Šé‡** | `models/transformer_lulu/best_model.pth` |
| **Reference Images** | `data/reference_images/lulu_pig_ref_*.jpg` |
| **API Keys é…ç½®** | `.env` (root directory) |
| **æ–‡æª”** | `docs/` |
| **PRD** | `docs/prd.md` |

---

## Cleanup Recommendations

### High Priority
1. âš ï¸ æ¸…ç† Obj 3 å¯¦é©—è…³æœ¬ï¼ˆä¿ç•™ Exp #11v2 + 1-2 å€‹é—œéµå¯¦é©—ï¼‰
2. âš ï¸ æ•´ç†æ•¸æ“šé›†ç‰ˆæœ¬ï¼ˆä¿ç•™ production_sales + 1 å€‹å‚™ä»½ï¼‰
3. âš ï¸ ç§»é™¤æˆ–å°å­˜ `obj2_midjourney_api/ttapi_client.py`

### Medium Priority
4. âš ï¸ çµ±ä¸€æ¸¬è©¦è…³æœ¬è‡³ `tests/` ç›®éŒ„
5. âš ï¸ å»ºç«‹ `scripts/` å·¥å…·è…³æœ¬ï¼ˆéƒ¨ç½²ã€æ¸…ç†ã€æ•¸æ“šç”Ÿæˆï¼‰

### Low Priority
6. âš ï¸ ä¸Šå‚³æ¨¡å‹æ¬Šé‡è‡³ Hugging Face Hub
7. âš ï¸ ä½¿ç”¨ Git LFS ç®¡ç†å¤§å‹æª”æ¡ˆ

---

**Document Owner:** Architect (Winston)
**Last Review:** 2025-11-06
**Next Review:** After Obj 4 completion
