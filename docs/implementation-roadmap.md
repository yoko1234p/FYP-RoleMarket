# å¯¦æ–½è·¯ç·šåœ– (Implementation Roadmap)

**å°ˆæ¡ˆåç¨±ï¼š** AI-Driven Market-Informed Character IP Design Extension and Demand Forecasting System

**ç¸½æ™‚é•·ï¼š** 17-18 å¤©ï¼ˆ2.5 é€±ï¼‰

**æœ€å¾Œæ›´æ–°ï¼š** 2025-11-06

---

## ğŸ“‹ ç¸½è¦½

### æ™‚é–“åˆ†é…
- **Obj 1 (NLP Prompt):** Day 1-3 (3 å¤©) - âœ… **å®Œæˆ**
- **Obj 2 (Midjourney API Integration):** Day 4-5 (2 å¤©) - âœ… **å®Œæˆï¼ˆç¯€çœ 2 å¤©!ï¼‰**
- **Obj 3 (Transformer Forecast):** Day 6-15 (10 å¤©) - âœ… **å®Œæˆï¼ˆExp #11v2: RÂ² = 0.6788ï¼‰**
- **Obj 4 (Web Integration):** Day 10-18 (9 å¤©) - âœ… **å®Œæˆï¼ˆ2025-11-06ï¼‰**
  - âœ… Story 4.1: Streamlit åŸºç¤ + Obj 1 æ•´åˆ
  - âœ… Story 4.2: Obj 2 åœ–ç‰‡ç”Ÿæˆæ•´åˆ
  - âœ… Story 4.3: Obj 3 éŠ·é‡é æ¸¬æ•´åˆ
  - âœ… Enhancement: Google Trends è‡ªå‹•æå–
- **Testing & Documentation:** Day 13-15 (3 å¤©) - ğŸ”„ **é€²è¡Œä¸­**
- **Bug Fixes & Polish:** Day 16-18 (3 å¤©) - â³ **å¾…é€²è¡Œ**
- **Deployment:** Day 19-20 (2 å¤©) - â³ **å¾…é€²è¡Œ**

### é—œéµé‡Œç¨‹ç¢‘
- âœ… **M1 (Day 3):** NLP æµç¨‹å¯ç”Ÿæˆæœ‰æ•ˆ Midjourney prompts
- âœ… **M2 (Day 5):** Midjourney API é›†æˆå®Œæˆï¼Œ28 å¼µè¨­è¨ˆåœ–ç”Ÿæˆä¸¦æå– CLIP embeddings - **ç¯€çœ 2 å¤©!**
- âœ… **M3 (Day 15):** éœ€æ±‚é æ¸¬æ¨¡å‹å®Œæˆï¼ˆTransformer RÂ² = 0.6788ï¼‰- **è¶…è¶Šç›®æ¨™ (â‰¥0.65)!**
- âœ… **M4 (Day 18):** å®Œæ•´ Web App åŠŸèƒ½å®Œæˆï¼ˆObj 1-3 æ•´åˆï¼‰- **å®Œæˆ!**
- ğŸ”„ **M5 (Day 20):** æ‰‹å‹•æ¸¬è©¦å®Œæˆï¼Œbugs ä¿®å¾©
- â³ **M6 (Day 22):** Streamlit Cloud éƒ¨ç½²å®Œæˆ
- â³ **M7 (Day 24):** Demo å½±ç‰‡å®Œæˆï¼Œæ–‡æª”é½Šå…¨

---

## ğŸš€ Day 0: å‰æœŸæº–å‚™ (Pre-launch)

### ä»»å‹™æ¸…å–®
- [ ] **å¸³è™Ÿè¨»å†Šï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰**
  - **ğŸ”¥ TTAPI å¸³è™Ÿ + Midjourney API Quota è³¼è²·** (https://ttapi.io) - **æœ€é«˜å„ªå…ˆç´š!**
    - è¨»å†Š TTAPI å¸³è™Ÿ
    - é¸æ“‡ PPU (Pay Per Use) æ¨¡å¼
    - è³¼è²·åˆå§‹ quota (~$10-30 é ç®—)
    - ç”Ÿæˆ API key ä¸¦æ¸¬è©¦åŸºæœ¬ /imagine èª¿ç”¨
    - è¨˜éŒ„ç¢ºåˆ‡ quota å®šåƒ¹ä¾›å ±å‘Šæˆæœ¬åˆ†æ
  - GPT_API_free (https://github.com/chatanywhere/GPT_API_free)
  - Hugging Face å¸³è™Ÿ + API Tokenï¼ˆç”¨æ–¼ CLIP æ¨¡å‹ï¼‰
  - Google Cloud å¸³è™Ÿï¼ˆGoogle Trends API å¦‚éœ€è¦ï¼‰

- [ ] **é–‹ç™¼ç’°å¢ƒè¨­ç½®**
  - Python 3.9+ å®‰è£
  - Git è¨­ç½® + å»ºç«‹å°ˆæ¡ˆ repo
  - å®‰è£åŸºç¤å¥—ä»¶ï¼š
    ```bash
    pip install pytrends openai pandas numpy matplotlib scikit-learn
    pip install torch torchvision transformers  # CLIP æ¨¡å‹ï¼Œç§»é™¤ diffusers å’Œ peft
    pip install streamlit plotly requests  # Streamlit + TTAPI èª¿ç”¨
    ```

- [ ] **Pikachu åƒè€ƒåœ–ç‰‡é¸æ“‡**ï¼ˆå–ä»£ ToyzeroPlus è¨“ç·´é›†ï¼‰
  - æœå°‹é«˜è³ªé‡ Pikachu åœ–ç‰‡ï¼ˆå®˜æ–¹ PokÃ©mon ä¾†æºã€DeviantArtã€Pinterestï¼‰
  - ç›®æ¨™ï¼š**1-2 å¼µåƒè€ƒåœ–ç‰‡**ï¼ˆé«˜è§£æåº¦ï¼Œæ¸…æ™°ç‰¹å¾µï¼‰
  - æ¸¬è©¦å¤šå¼µåœ–ç‰‡çš„ Midjourney cref åƒæ•¸æ•ˆæœ
  - ä¸Šå‚³è‡³å…¬é–‹å¯è¨ªå• URLï¼ˆcref åƒæ•¸è¦æ±‚ï¼‰
  - ä¸‹è¼‰ä¸¦æ•´ç†è‡³ `data/reference_images/` ç›®éŒ„

- [ ] **æ–‡æª”çµæ§‹å»ºç«‹**
  ```
  /FYP-RoleMarket
  â”œâ”€â”€ docs/
  â”‚   â”œâ”€â”€ brainstorming-session-results.md âœ…
  â”‚   â”œâ”€â”€ implementation-roadmap.md (æ­¤æ–‡ä»¶)
  â”‚   â”œâ”€â”€ experiment-logs/
  â”‚   â””â”€â”€ final-report/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ obj1_nlp_prompt/
  â”‚   â”œâ”€â”€ obj2_midjourney_api/  # å¾ obj2_lora_training æ”¹å
  â”‚   â”œâ”€â”€ obj3_lstm_forecast/
  â”‚   â””â”€â”€ obj4_web_app/
  â”œâ”€â”€ data/
  â”‚   â”œâ”€â”€ trends/
  â”‚   â”œâ”€â”€ reference_images/  # å¾ training_images æ”¹å
  â”‚   â”œâ”€â”€ generated_designs/  # æ–°å¢ï¼šå­˜æ”¾ Midjourney ç”Ÿæˆåœ–ç‰‡
  â”‚   â”œâ”€â”€ simulated_sales/
  â”‚   â””â”€â”€ clip_embeddings/
  â””â”€â”€ tests/
  ```

### å®Œæˆæ¨™æº–
- âœ… æ‰€æœ‰å¸³è™Ÿè¨»å†Šå®Œæˆä¸¦æ¸¬è©¦å¯è¨ªå•ï¼ˆç‰¹åˆ¥æ˜¯ TTAPI API key å¯æ­£å¸¸èª¿ç”¨ï¼‰
- âœ… Python ç’°å¢ƒå¯é‹è¡ŒåŸºç¤å¥—ä»¶
- âœ… é¸æ“‡ä¸¦æº–å‚™ 1-2 å¼µ Pikachu åƒè€ƒåœ–ç‰‡
- âœ… å°ˆæ¡ˆçµæ§‹å»ºç«‹å®Œæˆ
- âœ… TTAPI quota å·²è³¼è²·ä¸¦è¨˜éŒ„å®šåƒ¹

### é¢¨éšªèˆ‡ç·©è§£
| é¢¨éšª | ç·©è§£ç­–ç•¥ |
|------|----------|
| GPT_API_free ç„¡æ³•è¨ªå• | æº–å‚™ Hugging Face ä¸Šçš„ Mistral-7B ä½œå‚™æ¡ˆ |
| TTAPI quota å®šåƒ¹è¶…å‡ºé ç®— | é å…ˆç¢ºèªå®šåƒ¹ï¼Œå¦‚è¶…å‡º $30 å‰‡é™ä½ç”Ÿæˆåœ–ç‰‡æ•¸é‡ï¼ˆ7 themes Ã— 2 images = 14 å¼µï¼‰ |
| Pikachu åƒè€ƒåœ–ç‰‡ cref æ•ˆæœä¸ä½³ | æº–å‚™ 3-5 å¼µå€™é¸åœ–ç‰‡é€²è¡Œ A/B æ¸¬è©¦ï¼Œé¸æ“‡ cref ä¸€è‡´æ€§æœ€é«˜çš„ |

---

## ğŸ“… Objective 1: NLP Prompt ç”Ÿæˆ (Day 1-3)

### Day 1: Google Trends æ•¸æ“šæå–

**ç›®æ¨™ï¼š** å»ºç«‹ pytrends â†’ é—œéµå­—æå– pipeline

**ä»»å‹™ï¼š**
1. **pytrends è¨­ç½®å’Œæ¸¬è©¦ (2 hrs)**
   ```python
   from pytrends.request import TrendReq
   pytrend = TrendReq(hl='zh-TW', tz=360)

   # æ¸¬è©¦æŸ¥è©¢
   keywords = ['å¯µç‰©', 'å¯æ„›', 'è¬è–ç¯€', 'è–èª•ç¯€']
   pytrend.build_payload(keywords, timeframe='today 3-m')
   trends_data = pytrend.interest_over_time()
   ```

2. **å®šç¾©è¶¨å‹¢æŸ¥è©¢åƒæ•¸ (2 hrs)**
   - ç¢ºå®šæŸ¥è©¢é¡åˆ¥ï¼ˆå¯µç‰©ã€ç¯€æ—¥ã€æ–‡åŒ–ã€æµè¡Œæ–‡åŒ–ç­‰ï¼‰
   - è¨­å®šæ™‚é–“ç¯„åœï¼ˆéå» 3-6 å€‹æœˆï¼‰
   - æ¸¬è©¦å¤šçµ„é—œéµå­—çµ„åˆ

3. **TF-IDF é—œéµå­—æå– (3 hrs)**
   ```python
   from sklearn.feature_extraction.text import TfidfVectorizer

   # æå– top 10 é—œéµå­—
   vectorizer = TfidfVectorizer(max_features=10)
   tfidf_matrix = vectorizer.fit_transform(trend_texts)
   keywords = vectorizer.get_feature_names_out()
   ```

4. **å¯¦é©—è¨˜éŒ„ (1 hr)**
   - è¨˜éŒ„ä¸åŒæŸ¥è©¢åƒæ•¸çš„çµæœ
   - è©•ä¼°é—œéµå­—è³ªé‡ï¼ˆrelevance, diversityï¼‰

**äº¤ä»˜æˆæœï¼š**
- âœ… `src/obj1_nlp_prompt/trends_extractor.py`
- âœ… `data/trends/sample_trends_2025Q1.csv`
- âœ… `docs/experiment-logs/day1-trends-extraction.md`

**å®Œæˆæ¨™æº–ï¼š**
- å¯ç©©å®šæå– 10-15 å€‹æœ‰æ„ç¾©çš„è¶¨å‹¢é—œéµå­—
- é—œéµå­—æ¶µè“‹è¦–è¦ºå…ƒç´ å’Œæƒ…æ„Ÿ/æ°›åœ

---

### Day 2: LLM Prompt ç”Ÿæˆ

**ç›®æ¨™ï¼š** GPT_API_free â†’ å®Œæ•´ SDXL prompt

**ä»»å‹™ï¼š**
1. **GPT_API_free æ•´åˆ (2 hrs)**
   ```python
   import openai

   openai.api_base = "https://api.chatanywhere.org/v1"
   openai.api_key = "YOUR_API_KEY"

   # æ¸¬è©¦å‘¼å«
   response = openai.ChatCompletion.create(
       model="gpt-3.5-turbo",
       messages=[{"role": "user", "content": "Test"}]
   )
   ```

2. **Prompt Template è¨­è¨ˆ (3 hrs)**
   ```python
   PROMPT_TEMPLATE = """
   You are a professional character design prompt engineer for SDXL.

   Character Base: {character_name} - {character_description}

   Trending Keywords: {trend_keywords}

   Generate a detailed SDXL prompt that:
   1. Maintains character consistency (appearance, colors, features)
   2. Incorporates trending elements naturally
   3. Specifies emotional atmosphere
   4. Includes visual style and composition

   Format:
   - Main subject: [character + trend integration]
   - Style: [artistic style, mood]
   - Composition: [layout, perspective]
   - Details: [accessories, background, lighting]
   - Quality tags: [8k, detailed, professional]
   """
   ```

3. **ç”Ÿæˆæ¸¬è©¦èˆ‡å„ªåŒ– (3 hrs)**
   - æ¸¬è©¦ 10 çµ„ä¸åŒè¶¨å‹¢é—œéµå­—
   - è©•ä¼°ç”Ÿæˆ prompt çš„è³ªé‡ï¼ˆæ¸…æ™°åº¦ã€å‰µæ„åº¦ï¼‰
   - èª¿æ•´ template ä»¥æ”¹å–„è¼¸å‡º

4. **è² é¢ Prompt è¨­è¨ˆ (1 hr)**
   ```python
   NEGATIVE_PROMPT = "blurry, low quality, distorted, ugly, bad anatomy, watermark, text, duplicate, mutated, extra limbs"
   ```

**äº¤ä»˜æˆæœï¼š**
- âœ… `src/obj1_nlp_prompt/prompt_generator.py`
- âœ… `data/trends/generated_prompts_samples.json`
- âœ… `docs/experiment-logs/day2-prompt-generation.md`

**å®Œæˆæ¨™æº–ï¼š**
- LLM å¯ç©©å®šç”Ÿæˆçµæ§‹åŒ– SDXL prompt
- Prompt åŒ…å«è§’è‰²æè¿°ã€è¶¨å‹¢å…ƒç´ ã€æƒ…æ„Ÿæ°›åœã€è¦–è¦ºé¢¨æ ¼

---

### Day 3: å®Œæ•´æµç¨‹æ¸¬è©¦

**ç›®æ¨™ï¼š** End-to-end pipeline é©—è­‰

**ä»»å‹™ï¼š**
1. **æ•´åˆæ¸¬è©¦ (3 hrs)**
   ```python
   # å®Œæ•´æµç¨‹
   trends = extract_google_trends(keywords=['å¯µç‰©', 'æ˜¥ç¯€'])
   top_keywords = extract_tfidf_keywords(trends, top_n=10)
   prompt = generate_sdxl_prompt(
       character="ToyzeroPlusç†Šä»”",
       character_desc="å¯æ„›æ£•è‰²å°ç†Šï¼Œåœ“åœ“å¤§çœ¼ç›ï¼Œç©¿ç´…è‰²è¡£æœ",
       trend_keywords=top_keywords
   )
   print(prompt)
   ```

2. **å¤šå­£ç¯€æ¸¬è©¦ (3 hrs)**
   - æ¸¬è©¦ 4 å€‹å­£ç¯€å ´æ™¯ï¼ˆæ˜¥å¤ç§‹å†¬ï¼‰
   - æ¸¬è©¦ 3 å€‹ç¯€æ—¥å ´æ™¯ï¼ˆè–èª•ã€è¬è–ç¯€ã€è¾²æ›†æ–°å¹´ï¼‰
   - è¨˜éŒ„æ¯å€‹å ´æ™¯çš„ prompt è³ªé‡

3. **è¼¸å‡ºé©—è­‰ (2 hrs)**
   - äººå·¥è©•ä¼° prompt çš„å¯è¡Œæ€§
   - æª¢æŸ¥æ˜¯å¦ä¿æŒè§’è‰²ä¸€è‡´æ€§æè¿°
   - é©—è­‰è¶¨å‹¢å…ƒç´ èåˆè‡ªç„¶åº¦

4. **æ–‡æª”æ•´ç† (1 hr)**
   - æ’°å¯« Obj 1 å®Œæˆå ±å‘Š
   - è¨˜éŒ„å­¸ç¿’åˆ°çš„æœ€ä½³å¯¦è¸
   - æº–å‚™é€²å…¥ Obj 2 çš„ prompt ç¯„ä¾‹

**äº¤ä»˜æˆæœï¼š**
- âœ… `src/obj1_nlp_prompt/pipeline.py` (å®Œæ•´æµç¨‹)
- âœ… `data/trends/seasonal_prompts.json` (7 å€‹å ´æ™¯ç¯„ä¾‹)
- âœ… `docs/experiment-logs/day3-pipeline-validation.md`
- âœ… **Milestone M1 é”æˆ**

**å®Œæˆæ¨™æº–ï¼š**
- å¯åœ¨ 5 åˆ†é˜å…§å¾è¶¨å‹¢é—œéµå­—ç”Ÿæˆå®Œæ•´ SDXL prompt
- 7 å€‹æ¸¬è©¦å ´æ™¯å…¨éƒ¨é€šéè³ªé‡æª¢æŸ¥
- æº–å‚™å¥½é€²å…¥ Obj 2 çš„è¨“ç·´ prompt

---

## ğŸ¨ Objective 2: Midjourney API é›†æˆ (Day 4-5)

### Day 4: TTAPI è¨­ç½®èˆ‡ Character Reference æ¸¬è©¦

**ç›®æ¨™ï¼š** å®Œæˆ TTAPI Midjourney API é›†æˆä¸¦é©—è­‰ cref åƒæ•¸ä¸€è‡´æ€§

**ä»»å‹™ï¼š**
1. **TTAPI API åŸºç¤æ¸¬è©¦ (2 hrs)**
   ```python
   import requests
   import time

   # TTAPI Midjourney API é…ç½®
   API_KEY = "your_ttapi_key"
   BASE_URL = "https://api.ttapi.io/midjourney/v1"

   headers = {
       "TT-API-KEY": API_KEY,
       "Content-Type": "application/json"
   }

   # æ¸¬è©¦åŸºæœ¬ imagine èª¿ç”¨
   def test_basic_imagine():
       payload = {
           "prompt": "a cute Pikachu, cartoon style --v 6.0",
           "mode": "fast",  # 90 ç§’æ¨¡å¼
       }
       response = requests.post(f"{BASE_URL}/imagine", json=payload, headers=headers)
       job_id = response.json()["job_id"]

       # è¼ªè©¢çµæœ
       while True:
           result = requests.get(f"{BASE_URL}/fetch?job_id={job_id}", headers=headers)
           if result.json()["status"] == "completed":
               return result.json()["image_url"]
           time.sleep(10)
   ```

2. **Pikachu åƒè€ƒåœ–ç‰‡ cref æ¸¬è©¦ (3 hrs)**
   - é¸æ“‡ 3-5 å¼µå€™é¸ Pikachu åƒè€ƒåœ–ç‰‡
   - ä¸Šå‚³è‡³å…¬é–‹å¯è¨ªå• URLï¼ˆå¦‚ GitHub raw, Imgurï¼‰
   - æ¸¬è©¦æ¯å¼µåœ–ç‰‡çš„ cref ä¸€è‡´æ€§ï¼š
   ```python
   def test_cref_consistency(ref_image_url):
       # ä½¿ç”¨ç›¸åŒ prompt + cref ç”Ÿæˆ 4 å¼µåœ–ç‰‡
       prompt = f"a cute Pikachu wearing winter coat --cref {ref_image_url} --v 6.0"

       results = []
       for i in range(4):
           payload = {
               "prompt": prompt,
               "mode": "fast",
           }
           image_url = call_midjourney_api(payload)
           results.append(image_url)

       return results  # äººå·¥æª¢æŸ¥ä¸€è‡´æ€§
   ```
   - è©•ä¼°æ¨™æº–ï¼š
     - è§’è‰²ç‰¹å¾µä¸€è‡´æ€§ï¼ˆè‡‰éƒ¨ã€èº«é«”æ¯”ä¾‹ã€é¡è‰²ï¼‰
     - é¢¨æ ¼ä¸€è‡´æ€§ï¼ˆå¡é€šé¢¨æ ¼ã€ç·šæ¢ï¼‰
     - é…é£¾/æœè£è®ŠåŒ–çš„éˆæ´»æ€§
   - é¸æ“‡æœ€ä½³çš„ 1-2 å¼µåƒè€ƒåœ–ç‰‡

3. **CLIP Similarity é©—è­‰å·¥å…· (2 hrs)**
   ```python
   from transformers import CLIPProcessor, CLIPModel
   from PIL import Image
   import torch

   model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
   processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")

   def compute_clip_similarity(img1_path, img2_path):
       img1 = Image.open(img1_path)
       img2 = Image.open(img2_path)

       inputs = processor(images=[img1, img2], return_tensors="pt")
       with torch.no_grad():
           features = model.get_image_features(**inputs)

       # Cosine similarity
       similarity = torch.nn.functional.cosine_similarity(
           features[0].unsqueeze(0),
           features[1].unsqueeze(0)
       )
       return similarity.item()

   # æ¸¬è©¦ cref ç”Ÿæˆåœ–ç‰‡ä¹‹é–“çš„ç›¸ä¼¼åº¦
   def validate_cref_results(generated_images):
       similarities = []
       for i in range(len(generated_images)):
           for j in range(i+1, len(generated_images)):
               sim = compute_clip_similarity(generated_images[i], generated_images[j])
               similarities.append(sim)

       avg_similarity = np.mean(similarities)
       print(f"å¹³å‡ CLIP ç›¸ä¼¼åº¦: {avg_similarity:.3f}")
       # ç›®æ¨™: > 0.75 è¡¨ç¤ºæ ¸å¿ƒç‰¹å¾µä¸€è‡´ï¼Œ> 0.60 è¡¨ç¤ºé¢¨æ ¼ä¸€è‡´
       return avg_similarity
   ```

4. **API é€Ÿç‡é™åˆ¶èˆ‡æˆæœ¬æ¸¬è©¦ (1 hr)**
   - æ¸¬è©¦æœ€å¤§ä½µç™¼è«‹æ±‚æ•¸ï¼ˆå®˜æ–¹ä¸Šé™ï¼š10 concurrent jobsï¼‰
   - è¨˜éŒ„å–®æ¬¡ imagine èª¿ç”¨çš„å¯¦éš›æˆæœ¬
   - è¨ˆç®— 28 å¼µåœ–ç‰‡ï¼ˆ7 themes Ã— 4 imagesï¼‰çš„ç¸½æˆæœ¬
   - ç¢ºèªé ç®—åœ¨ $10-30 ç¯„åœå…§

**äº¤ä»˜æˆæœï¼š**
- âœ… `src/obj2_midjourney_api/ttapi_client.py` (TTAPI èª¿ç”¨å°è£)
- âœ… `data/reference_images/selected_pikachu_refs/` (1-2 å¼µæœ€çµ‚é¸æ“‡çš„åƒè€ƒåœ–ç‰‡)
- âœ… `docs/experiment-logs/day4-cref-testing.md` (cref æ¸¬è©¦å ±å‘Š)

**å®Œæˆæ¨™æº–ï¼š**
- TTAPI API å¯æ­£å¸¸èª¿ç”¨ä¸¦è¿”å›åœ–ç‰‡
- é¸æ“‡çš„ Pikachu åƒè€ƒåœ–ç‰‡ cref ä¸€è‡´æ€§ > 0.75ï¼ˆCLIP similarityï¼‰
- æˆæœ¬ä¼°ç®—å®Œæˆï¼Œç¢ºèªåœ¨é ç®—å…§
- CLIP similarity é©—è­‰å·¥å…·å¯æ­£å¸¸é‹è¡Œ

---

### Day 5: æ‰¹é‡è¨­è¨ˆç”Ÿæˆèˆ‡ CLIP Embeddings æå–

**ç›®æ¨™ï¼š** ä½¿ç”¨ Midjourney API ç”Ÿæˆ 28 å¼µè¨­è¨ˆåœ–ä¸¦æå– CLIP embeddingsï¼ˆä¾› Obj 3 ä½¿ç”¨ï¼‰

**ä»»å‹™ï¼š**
1. **æ‰¹é‡ç”Ÿæˆè…³æœ¬å¯¦ä½œ (2 hrs)**
   ```python
   # ä½¿ç”¨ Obj 1 ç”Ÿæˆçš„ 7 å€‹å­£ç¯€ prompts
   seasonal_prompts = [
       "a cute Pikachu wearing winter coat, snowing background",
       "a cute Pikachu at beach, summer vibe",
       "a cute Pikachu with Halloween pumpkin, spooky theme",
       # ... å…¶é¤˜ 4 å€‹
   ]

   REFERENCE_IMAGE_URL = "https://your-domain.com/pikachu_ref.png"

   def batch_generate_designs():
       all_results = []

       for prompt_id, base_prompt in enumerate(seasonal_prompts):
           # æ¯å€‹ prompt ç”Ÿæˆ 4 å¼µè®ŠåŒ–
           prompt_with_cref = f"{base_prompt} --cref {REFERENCE_IMAGE_URL} --v 6.0"

           for variation_id in range(4):
               payload = {
                   "prompt": prompt_with_cref,
                   "mode": "fast",  # 90 ç§’/å¼µ
               }

               image_url = call_midjourney_api(payload)

               # ä¸‹è¼‰ä¸¦ä¿å­˜
               image = download_image(image_url)
               save_path = f"data/generated_designs/theme{prompt_id}_var{variation_id}.png"
               image.save(save_path)

               all_results.append({
                   "theme_id": prompt_id,
                   "variation_id": variation_id,
                   "prompt": base_prompt,
                   "image_path": save_path,
                   "midjourney_url": image_url
               })

               # é¿å…é€Ÿç‡é™åˆ¶ï¼ˆ10 concurrent jobsï¼‰
               if len(all_results) % 10 == 0:
                   time.sleep(30)  # æ¯ 10 å¼µç¨ä½œæš«åœ

       return all_results  # Total: 28 å¼µ
   ```

2. **åŸ·è¡Œæ‰¹é‡ç”Ÿæˆ (4 hrs)**
   - é‹è¡Œ batch_generate_designs()
   - é è¨ˆæ™‚é–“ï¼š28 å¼µ Ã— 90 ç§’ = 42 åˆ†é˜ï¼ˆfast modeï¼‰
   - åŒ…å«ä¸‹è¼‰å’Œä¿å­˜æ™‚é–“ï¼Œç¸½è¨ˆç´„ 1.5-2 å°æ™‚
   - ç›£æ§ API éŒ¯èª¤ä¸¦è‡ªå‹•é‡è©¦
   - è¨˜éŒ„å¯¦éš›æˆæœ¬

3. **è³ªé‡äººå·¥æª¢æŸ¥ (1 hr)**
   - æª¢æŸ¥æ‰€æœ‰ 28 å¼µåœ–ç‰‡ï¼š
     - è§’è‰²ä¸€è‡´æ€§ï¼ˆPikachu ç‰¹å¾µæ˜¯å¦ä¿ç•™ï¼‰
     - ä¸»é¡ŒåŒ¹é…åº¦ï¼ˆæ˜¯å¦ç¬¦åˆå­£ç¯€/ç¯€æ—¥ä¸»é¡Œï¼‰
     - è—è¡“è³ªé‡ï¼ˆæ§‹åœ–ã€å…‰ç·šã€ç´°ç¯€ï¼‰
   - å¦‚æœ‰æ˜é¡¯å¤±æ•—æ¡ˆä¾‹ï¼Œé‡æ–°ç”Ÿæˆï¼ˆé ç•™ 2-3 æ¬¡é‡è©¦ quotaï¼‰

4. **CLIP Embeddings æ‰¹é‡æå– (2 hrs)**
   ```python
   def extract_all_clip_embeddings(image_paths):
       embeddings_db = {}

       for img_path in image_paths:
           image = Image.open(img_path)
           inputs = processor(images=image, return_tensors="pt")

           with torch.no_grad():
               features = model.get_image_features(**inputs)

           # ä¿å­˜ç‚º numpy array (768-dim for CLIP-Large)
           embeddings_db[img_path] = features.cpu().numpy().squeeze()

       # ä¿å­˜ç‚º .npy æª”æ¡ˆä¾› Obj 3 ä½¿ç”¨
       np.save("data/clip_embeddings/design_features.npy", embeddings_db)

       print(f"æå–å®Œæˆï¼š{len(embeddings_db)} å€‹ embeddings")
       print(f"Shape: {list(embeddings_db.values())[0].shape}")  # (768,)

       return embeddings_db
   ```

5. **Obj 2 å®Œæˆå ±å‘Šæ’°å¯« (1 hr)**
   - ç¸½çµ TTAPI é›†æˆéç¨‹
   - cref åƒæ•¸ä¸€è‡´æ€§è©•ä¼°çµæœ
   - å¯¦éš›æˆæœ¬å ±å‘Šï¼ˆvs $10-30 é ç®—ï¼‰
   - 28 å¼µè¨­è¨ˆåœ–å±•ç¤ºï¼ˆmarkdown galleryï¼‰
   - CLIP embeddings æå–çµ±è¨ˆ
   - å•†æ¥­å¯è¡Œæ€§åˆ†æï¼ˆvs LoRA æ–¹æ³•çš„æ™‚é–“/æˆæœ¬å„ªå‹¢ï¼‰

**äº¤ä»˜æˆæœï¼š**
- âœ… `data/generated_designs/` (28 å¼µè¨­è¨ˆåœ–)
- âœ… `data/clip_embeddings/design_features.npy` (28 Ã— 768 embeddings)
- âœ… `src/obj2_midjourney_api/batch_generator.py`
- âœ… `docs/experiment-logs/day5-batch-generation.md`
- âœ… **Milestone M2 é”æˆ**

**å®Œæˆæ¨™æº–ï¼š**
- 28 å¼µè¨­è¨ˆåœ–å…¨éƒ¨ç”Ÿæˆå®Œæˆï¼ˆ7 themes Ã— 4 variationsï¼‰
- è§’è‰²ä¸€è‡´æ€§é€šéäººå·¥æª¢æŸ¥ï¼ˆ> 90% å¯è¾¨è­˜ç‚º Pikachuï¼‰
- CLIP embeddings æˆåŠŸæå–ä¸¦ä¿å­˜ï¼ˆshape: 28 Ã— 768ï¼‰
- å¯¦éš›æˆæœ¬åœ¨ $10-30 é ç®—å…§
- Obj 2 å®Œæˆå ±å‘Šæ’°å¯«å®Œç•¢

---

## ğŸ“Š Objective 3: Transformer éœ€æ±‚é æ¸¬ (Day 6-15) âœ… å®Œæˆ

**æœ€çµ‚æˆæœï¼š** Hybrid Transformer Model (Exp #11v2) - RÂ² = 0.6788, MAE = 327.26, RMSE = 456.40

**é—œéµç™¼ç¾ï¼š**
- âœ… Transformer æ¶æ§‹å„ªæ–¼å‚³çµ± LSTMï¼ˆRÂ² 0.6788 vs åŸºç·š 0.5127ï¼‰
- âœ… é”åˆ°ä¼æ¥­ç´šæ¨™æº–ï¼ˆRÂ² â‰¥ 0.65ï¼‰
- âœ… Ensemble å’Œæ•¸æ“šå¢å¼·å¯¦é©—è­‰å¯¦å–®æ¨¡å‹å·²é”æœ€ä½³å¹³è¡¡
- âœ… å®Œæ•´å¯¦é©—è¨˜éŒ„ï¼š[`docs/experiment-log-lulu-transformer.md`](experiment-log-lulu-transformer.md)

**æœ€çµ‚é…ç½®ï¼š**
- Model: Hybrid Transformer (D_MODEL=64, NUM_LAYERS=2, NHEAD=8)
- Training: 400 epochs (early stop at 155), PATIENCE=80
- Dataset: Lulu Pig (1,075 records, original data)
- Features: Time-series trends (4-quarter history) + CLIP embeddings (768-dim) + product type

### Day 6: æ¨¡æ“¬éŠ·å”®æ•¸æ“šç”Ÿæˆ

**ç›®æ¨™ï¼š** ç”Ÿæˆ 60 å€‹æ­·å²æ•¸æ“šé»ï¼ˆæƒ…æ™¯ Bï¼šrule-basedï¼‰

**ä»»å‹™ï¼š**
1. **æ•¸æ“šçµæ§‹è¨­è¨ˆ (2 hrs)**
   ```python
   # æ¯å€‹æ•¸æ“šé»çš„çµæ§‹
   data_point = {
       "year": 2021,
       "season": "Spring",  # Spring, Summer, Fall, Winter
       "design_id": "design_001",
       "clip_embedding": np.array([...]),  # 768-dim
       "google_trends_history": [45, 52, 48, 50],  # éå» 3-4 å­£çš„è¶¨å‹¢åˆ†æ•¸
       "sales_quantity": 1250,  # å¯¦éš›éŠ·é‡ï¼ˆç›®æ¨™è®Šæ•¸ï¼‰
   }

   # ç¸½å…± 60 å€‹æ•¸æ“šé»
   # 5 years x 4 seasons x 3 designs per season = 60
   ```

2. **æ¨¡æ“¬è¦å‰‡å®šç¾© (3 hrs)**
   ```python
   def simulate_sales(design_embedding, trend_history, season, year):
       # Rule 1: Google Trends å½±éŸ¿ (30%)
       trend_factor = np.mean(trend_history) / 100 * 0.3

       # Rule 2: CLIP Similarity (èˆ‡éå¾€ç†±è³£è¨­è¨ˆ) (25%)
       similarity = compute_clip_similarity(design_embedding, hot_designs_db)
       similarity_factor = similarity * 0.25

       # Rule 3: å­£ç¯€å› ç´  (20%)
       seasonal_multiplier = {
           "Spring": 1.1, "Summer": 0.9, "Fall": 1.0, "Winter": 1.3
       }
       season_factor = seasonal_multiplier[season] * 0.2

       # Rule 4: ç”Ÿç”¢é™åˆ¶ (15%)
       production_cap = 2000

       # Rule 5: éš¨æ©Ÿå™ªéŸ³ (10%)
       noise = np.random.normal(0, 0.1)

       # è¨ˆç®—éŠ·é‡
       base_sales = 1000
       sales = base_sales * (1 + trend_factor + similarity_factor + season_factor + noise)
       sales = min(sales, production_cap)

       return int(sales)
   ```

3. **æ•¸æ“šç”ŸæˆåŸ·è¡Œ (3 hrs)**
   - ç‚º 5 å¹´ x 4 å­£ç”Ÿæˆ Google Trends æ•¸æ“šï¼ˆpytrends æˆ–æ¨¡æ“¬ï¼‰
   - ç”Ÿæˆ 60 å€‹è¨­è¨ˆçš„ CLIP embeddingsï¼ˆä½¿ç”¨ Day 7 çš„ 28 å¼µ + é¡å¤– 32 å¼µï¼‰
   - åŸ·è¡Œæ¨¡æ“¬è¦å‰‡ï¼Œç”ŸæˆéŠ·é‡æ•¸æ“š
   - é©—è­‰æ•¸æ“šåˆ†å¸ƒåˆç†æ€§ï¼ˆmean, std, rangeï¼‰

4. **æ•¸æ“šé©—è­‰èˆ‡å„²å­˜ (1 hr)**
   ```python
   import pandas as pd

   df = pd.DataFrame(sales_data)
   print(df.describe())
   df.to_csv("data/simulated_sales/historical_data.csv", index=False)
   np.save("data/simulated_sales/clip_embeddings.npy", all_embeddings)
   ```

**äº¤ä»˜æˆæœï¼š**
- âœ… `data/simulated_sales/historical_data.csv` (60 rows)
- âœ… `data/simulated_sales/clip_embeddings.npy` (60 x 768)
- âœ… `data/simulated_sales/trends_history.json`
- âœ… `docs/experiment-logs/day8-data-simulation.md`

**å®Œæˆæ¨™æº–ï¼š**
- 60 å€‹æ•¸æ“šé»ç”Ÿæˆå®Œæˆ
- éŠ·é‡åˆ†å¸ƒåˆç†ï¼ˆ500-2000 ç¯„åœï¼Œç¬¦åˆç¾å¯¦ï¼‰
- æ•¸æ“šåŒ…å«æ‰€æœ‰å¿…è¦ç‰¹å¾µï¼ˆtrends, CLIP, season, salesï¼‰

---

### Day 7-14: Hybrid Transformer æ¨¡å‹å¯¦ä½œèˆ‡å„ªåŒ–

**ç›®æ¨™ï¼š** å¯¦ä½œçµåˆ time-series å’Œ static features çš„ Transformer æ¶æ§‹ï¼ˆå·²å®Œæˆï¼‰

**ä»»å‹™ï¼š**
1. **æ•¸æ“šé è™•ç† (2 hrs)**
   ```python
   from sklearn.preprocessing import StandardScaler

   # Time-series features: Google Trends (éå» 3-4 å­£)
   X_time_series = []  # Shape: (60, 4, 1)

   # Static features: CLIP embeddings + season encoding
   X_static = []  # Shape: (60, 768+4)

   # Target
   y = df["sales_quantity"].values  # Shape: (60,)

   # æ¨™æº–åŒ–
   scaler_ts = StandardScaler()
   scaler_static = StandardScaler()
   X_time_series = scaler_ts.fit_transform(X_time_series.reshape(-1, 4)).reshape(-1, 4, 1)
   X_static = scaler_static.fit_transform(X_static)
   ```

2. **Hybrid LSTM æ¶æ§‹è¨­è¨ˆ (3 hrs)**
   ```python
   import torch
   import torch.nn as nn

   class HybridLSTM(nn.Module):
       def __init__(self, ts_input_dim=1, static_input_dim=772, hidden_dim=128):
           super(HybridLSTM, self).__init__()

           # LSTM åˆ†æ”¯ï¼ˆè™•ç†æ™‚é–“åºåˆ—ï¼‰
           self.lstm = nn.LSTM(ts_input_dim, hidden_dim, num_layers=2, batch_first=True)

           # éœæ…‹ç‰¹å¾µåˆ†æ”¯
           self.static_fc = nn.Sequential(
               nn.Linear(static_input_dim, 256),
               nn.ReLU(),
               nn.Dropout(0.3),
               nn.Linear(256, 128),
               nn.ReLU(),
           )

           # èåˆå±¤
           self.fusion = nn.Sequential(
               nn.Linear(hidden_dim + 128, 64),
               nn.ReLU(),
               nn.Dropout(0.2),
               nn.Linear(64, 1)
           )

       def forward(self, x_ts, x_static):
           # LSTM è™•ç†æ™‚é–“åºåˆ—
           lstm_out, (hn, cn) = self.lstm(x_ts)
           lstm_features = hn[-1]  # å–æœ€å¾Œä¸€å±¤çš„ hidden state

           # è™•ç†éœæ…‹ç‰¹å¾µ
           static_features = self.static_fc(x_static)

           # èåˆ
           combined = torch.cat([lstm_features, static_features], dim=1)
           output = self.fusion(combined)
           return output
   ```

3. **è¨“ç·´é‚è¼¯å¯¦ä½œ (3 hrs)**
   ```python
   from torch.utils.data import DataLoader, TensorDataset

   # è³‡æ–™åˆ†å‰²
   train_size = int(0.8 * len(X_time_series))
   X_ts_train, X_ts_test = X_time_series[:train_size], X_time_series[train_size:]
   X_static_train, X_static_test = X_static[:train_size], X_static[train_size:]
   y_train, y_test = y[:train_size], y[train_size:]

   # DataLoader
   train_dataset = TensorDataset(
       torch.FloatTensor(X_ts_train),
       torch.FloatTensor(X_static_train),
       torch.FloatTensor(y_train)
   )
   train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)

   # è¨“ç·´è¨­å®š
   model = HybridLSTM()
   criterion = nn.MSELoss()
   optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

   # è¨“ç·´è¿´åœˆ
   for epoch in range(100):
       model.train()
       for x_ts, x_static, y_batch in train_loader:
           optimizer.zero_grad()
           predictions = model(x_ts, x_static)
           loss = criterion(predictions.squeeze(), y_batch)
           loss.backward()
           optimizer.step()
   ```

4. **åˆæ­¥æ¸¬è©¦ (1 hr)**
   - åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼° MAE, RMSE, RÂ²
   - ç¹ªè£½é æ¸¬ vs å¯¦éš›åœ–è¡¨

**äº¤ä»˜æˆæœï¼š**
- âœ… `src/obj3_lstm_forecast/hybrid_lstm_model.py`
- âœ… `src/obj3_lstm_forecast/train.py`
- âœ… `docs/experiment-logs/day9-lstm-implementation.md`

**å®Œæˆæ¨™æº–ï¼š**
- Hybrid LSTM æ¨¡å‹å¯æˆåŠŸè¨“ç·´
- è¨“ç·´ loss æ”¶æ–‚
- ç¨‹å¼ç¢¼çµæ§‹æ¸…æ™°ï¼ŒåŒ…å«è¨»é‡‹

---

### Day 8: æ¨¡å‹è¨“ç·´èˆ‡ GRU å‚™æ¡ˆæ¸¬è©¦

**ç›®æ¨™ï¼š** å®Œæˆ LSTM è¨“ç·´ä¸¦æ¸¬è©¦ GRU ä½œå­¸è¡“æ¯”è¼ƒ

**ä»»å‹™ï¼š**
1. **LSTM å®Œæ•´è¨“ç·´ (3 hrs)**
   - ä½¿ç”¨ early stoppingï¼ˆç›£æ§ validation lossï¼‰
   - è¨˜éŒ„è¨“ç·´æ›²ç·šï¼ˆloss, MAE, RÂ²ï¼‰
   - ä¿å­˜æœ€ä½³æ¨¡å‹æ¬Šé‡

2. **GRU å‚™æ¡ˆå¯¦ä½œ (2 hrs)**
   ```python
   class HybridGRU(nn.Module):
       def __init__(self, ts_input_dim=1, static_input_dim=772, hidden_dim=128):
           super(HybridGRU, self).__init__()

           # GRU æ›¿ä»£ LSTM
           self.gru = nn.GRU(ts_input_dim, hidden_dim, num_layers=2, batch_first=True)

           # å…¶ä»–éƒ¨åˆ†ç›¸åŒ
           # ...
   ```
   - ä½¿ç”¨ç›¸åŒè¨“ç·´è¨­å®šè¨“ç·´ GRU
   - æ¯”è¼ƒ LSTM vs GRU çš„æ•ˆèƒ½

3. **æ¨¡å‹è©•ä¼° (2 hrs)**
   ```python
   from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

   # åœ¨æ¸¬è©¦é›†ä¸Šé æ¸¬
   model.eval()
   with torch.no_grad():
       predictions = model(X_ts_test_tensor, X_static_test_tensor)

   # è¨ˆç®—æŒ‡æ¨™
   mae = mean_absolute_error(y_test, predictions.numpy())
   rmse = np.sqrt(mean_squared_error(y_test, predictions.numpy()))
   r2 = r2_score(y_test, predictions.numpy())

   print(f"MAE: {mae:.2f}, RMSE: {rmse:.2f}, RÂ²: {r2:.3f}")
   ```

4. **å¯è¦–åŒ–çµæœ (2 hrs)**
   - é æ¸¬ vs å¯¦éš›æ•£é»åœ–
   - æ™‚é–“åºåˆ—é æ¸¬æ›²ç·š
   - æ®˜å·®åˆ†æåœ–

**äº¤ä»˜æˆæœï¼š**
- âœ… `models/lstm/best_model.pth`
- âœ… `models/gru/best_model.pth`
- âœ… `data/results/predictions_comparison.csv`
- âœ… `docs/experiment-logs/day10-model-training.md`

**å®Œæˆæ¨™æº–ï¼š**
- LSTM æ¸¬è©¦é›† RÂ² > 0.7ï¼ˆåˆç†é æ¸¬èƒ½åŠ›ï¼‰
- LSTM vs GRU æ¯”è¼ƒå ±å‘Šå®Œæˆ
- è¨“ç·´æ›²ç·šå’Œè©•ä¼°åœ–è¡¨ä¿å­˜

---

### Day 15: å¯¦é©—ç¸½çµèˆ‡æœ€çµ‚æ–¹æ¡ˆç¢ºèª

**ç›®æ¨™ï¼š** å®Œæˆæ‰€æœ‰å„ªåŒ–å¯¦é©—ä¸¦ç¢ºå®šæœ€çµ‚ç”Ÿç”¢æ–¹æ¡ˆï¼ˆå·²å®Œæˆï¼‰

**å®Œæˆä»»å‹™ï¼š**
1. **14+ æ¬¡å¯¦é©—è¿­ä»£ï¼ˆè©³è¦‹ `docs/experiment-log-lulu-transformer.md`ï¼‰**
   - Exp #3-9: æœ¬åœ°é–‹ç™¼èˆ‡å„ªåŒ–ï¼ˆGrid Search: RÂ² = 0.6313ï¼‰
   - Exp #10: Kaggle Baselineï¼ˆRÂ² = 0.5127ï¼Œè¨“ç·´ä¸è¶³ï¼‰
   - Exp #11v2: å»¶é•·è¨“ç·´ï¼ˆRÂ² = 0.6788ï¼‰- âœ… **æœ€çµ‚æ¡ç”¨**
   - Exp #12v3/v4: Ensemble æ–¹æ¡ˆï¼ˆRÂ² = 0.9525ï¼Œæ•¸æ“šæ´©æ¼ï¼‰
   - Exp #14: æ•¸æ“šå¢å¼·ï¼ˆRÂ² = 0.9737ï¼Œæ•¸æ“šæ´©æ¼ï¼‰

2. **Feature Importance åˆ†æï¼ˆå·²å®Œæˆï¼‰**
   ```python
   from captum.attr import IntegratedGradients

   # è¨ˆç®—æ¯å€‹ç‰¹å¾µçš„é‡è¦æ€§
   ig = IntegratedGradients(model)

   # Time-series features importance
   ts_attr = ig.attribute(X_ts_test_tensor, target=0)

   # Static features importance (CLIP + season)
   static_attr = ig.attribute(X_static_test_tensor, target=0)

   # å¯è¦–åŒ–
   import matplotlib.pyplot as plt
   plt.bar(range(len(static_attr.mean(0))), static_attr.mean(0).abs().numpy())
   plt.title("Feature Importance")
   ```

2. **æ•æ„Ÿåº¦åˆ†æ (2 hrs)**
   - æ”¹è®Š Google Trends åˆ†æ•¸ï¼ˆ+10%, -10%ï¼‰ï¼Œè§€å¯Ÿé æ¸¬è®ŠåŒ–
   - æ”¹è®Š CLIP similarityï¼ˆ+0.1, -0.1ï¼‰ï¼Œè§€å¯Ÿé æ¸¬è®ŠåŒ–
   - åˆ†æå“ªäº›å› ç´ æœ€å½±éŸ¿éŠ·é‡

3. **å¸‚å ´æ´å¯Ÿå ±å‘Šç”Ÿæˆ (2 hrs)**
   ```markdown
   ## LSTM é æ¸¬æ¨¡å‹æ´å¯Ÿå ±å‘Š

   ### å½±éŸ¿éŠ·é‡çš„é—œéµå› ç´ ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰
   1. Google Trends åˆ†æ•¸ï¼ˆ35% å½±éŸ¿ï¼‰
   2. è¨­è¨ˆè¦–è¦ºç›¸ä¼¼åº¦ï¼ˆ30% å½±éŸ¿ï¼‰
   3. å­£ç¯€å› ç´ ï¼ˆ20% å½±éŸ¿ï¼‰
   4. å…¶ä»–å› ç´ ï¼ˆ15% å½±éŸ¿ï¼‰

   ### å»ºè­°
   - æ˜¥å­£å’Œå†¬å­£æ˜¯æœ€ä½³ä¸Šå¸‚æ™‚æ©Ÿ
   - è¨­è¨ˆæ‡‰èˆ‡éå¾€ç†±è³£è§’è‰²ä¿æŒ 0.7+ ç›¸ä¼¼åº¦
   - Google Trends åˆ†æ•¸ > 50 çš„ä¸»é¡Œå„ªå…ˆè€ƒæ…®
   ```

4. **Obj 3 å®Œæˆå ±å‘Š (2 hrs)**
   - æ¨¡å‹æ¶æ§‹èªªæ˜
   - è¨“ç·´éç¨‹å’Œçµæœ
   - Feature importance ç™¼ç¾
   - çµ¦ Obj 4 çš„é æ¸¬ API æº–å‚™

**äº¤ä»˜æˆæœï¼š**
- âœ… `obj3_lstm_forecast/kaggle_train_lulu_exp11v2.py` (æœ€çµ‚ç”Ÿç”¢æ¨¡å‹)
- âœ… `obj3_lstm_forecast/generate_augmented_data.py` (æ•¸æ“šå¢å¼·æ¢ç´¢è…³æœ¬)
- âœ… `obj3_lstm_forecast/kaggle_train_lulu_exp14.py` (æ•¸æ“šå¢å¼·è¨“ç·´è…³æœ¬)
- âœ… `obj3_lstm_forecast/kaggle_train_lulu_exp12v3.py` (Ensemble æ¢ç´¢è…³æœ¬)
- âœ… `docs/experiment-log-lulu-transformer.md` (å®Œæ•´å¯¦é©—è¨˜éŒ„)
- âœ… **Milestone M3 é”æˆ**

**å®Œæˆæ¨™æº–ï¼š**
- âœ… Hybrid Transformer æ¨¡å‹é”åˆ°ä¼æ¥­ç´šæ¨™æº–ï¼ˆRÂ² = 0.6788 â‰¥ 0.65ï¼‰
- âœ… å®Œæˆ Ensemble å’Œæ•¸æ“šå¢å¼·æ–¹æ¡ˆé©—è­‰ï¼ˆç™¼ç¾æ•¸æ“šæ´©æ¼å•é¡Œï¼‰
- âœ… ç¢ºå®šæœ€çµ‚ç”Ÿç”¢æ–¹æ¡ˆï¼šExp #11v2 + åŸå§‹æ•¸æ“š
- âœ… å®Œæ•´å¯¦é©—è¨˜éŒ„æ–‡æª”æ’°å¯«å®Œç•¢
- âœ… é æ¸¬ API å¯è¢« Streamlit å‘¼å«

---

## ğŸŒ Objective 4: Web æ•´åˆ (Day 10-12)

### Day 10: Streamlit UI é–‹ç™¼

**ç›®æ¨™ï¼š** å»ºç«‹ Streamlit Web App ä»‹é¢

**ä»»å‹™ï¼š**
1. **å°ˆæ¡ˆæ¶æ§‹è¨­è¨ˆ (1 hr)**
   ```
   src/obj4_web_app/
   â”œâ”€â”€ app.py (ä¸»ç¨‹å¼)
   â”œâ”€â”€ pages/
   â”‚   â”œâ”€â”€ 1_ç”Ÿæˆè¨­è¨ˆ.py
   â”‚   â””â”€â”€ 2_é æ¸¬èˆ‡è¶¨å‹¢.py
   â”œâ”€â”€ utils/
   â”‚   â”œâ”€â”€ trends_api.py
   â”‚   â”œâ”€â”€ prompt_generator.py
   â”‚   â”œâ”€â”€ lstm_predictor.py
   â”‚   â””â”€â”€ hf_inference.py
   â””â”€â”€ config.py
   ```

2. **Page 1: ç”Ÿæˆè¨­è¨ˆä»‹é¢ (4 hrs)**
   ```python
   import streamlit as st

   st.title("ğŸ¨ AI è§’è‰²è¨­è¨ˆç”Ÿæˆå™¨")

   # è¶¨å‹¢é—œéµå­—è¼¸å…¥
   with st.expander("ğŸ“ˆ ç•¶å‰è¶¨å‹¢åˆ†æ"):
       keywords = st.text_input("è¼¸å…¥è¶¨å‹¢é—œéµå­—ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰", "å¯µç‰©, æ˜¥ç¯€, å¯æ„›")
       if st.button("åˆ†æè¶¨å‹¢"):
           trends_data = get_google_trends(keywords)
           st.line_chart(trends_data)

   # è§’è‰²è¨­å®š
   character_name = st.text_input("è§’è‰²åç¨±", "ToyzeroPlus Bear")
   character_desc = st.text_area("è§’è‰²æè¿°", "å¯æ„›æ£•è‰²å°ç†Š...")

   # ç”Ÿæˆè¨­è¨ˆ
   if st.button("ç”Ÿæˆè¨­è¨ˆ"):
       with st.spinner("æ­£åœ¨ç”Ÿæˆ prompt..."):
           prompt = generate_prompt(character_name, character_desc, keywords)
           st.code(prompt)

       with st.spinner("æ­£åœ¨ç”Ÿæˆåœ–ç‰‡ï¼ˆé€šé HF Inference APIï¼‰..."):
           images = generate_images_hf(prompt, num_images=4)

           cols = st.columns(4)
           for i, img in enumerate(images):
               cols[i].image(img, caption=f"è¨­è¨ˆ {i+1}")
   ```

3. **Page 2: é æ¸¬èˆ‡è¶¨å‹¢å„€è¡¨æ¿ (4 hrs)**
   ```python
   import streamlit as st
   import plotly.express as px

   st.title("ğŸ“Š éŠ·é‡é æ¸¬èˆ‡å¸‚å ´è¶¨å‹¢")

   # å­£ç¯€é¸æ“‡
   season = st.selectbox("é¸æ“‡å­£ç¯€", ["Spring", "Summer", "Fall", "Winter"])

   # é¡¯ç¤ºé æ¸¬
   if st.button("é æ¸¬éŠ·é‡"):
       # è¼‰å…¥ LSTM æ¨¡å‹
       predictions = predict_sales(season, current_trends, design_clip_features)

       # é¡¯ç¤ºé æ¸¬çµæœ
       st.metric("é æ¸¬éŠ·é‡", f"{int(predictions[0]):,} ä»¶")

       # æ­·å²å°æ¯”åœ–è¡¨
       fig = px.line(historical_sales, x="date", y="sales", title="æ­·å²éŠ·é‡è¶¨å‹¢")
       st.plotly_chart(fig)

       # å¸‚å ´æ´å¯Ÿ
       st.subheader("ğŸ’¡ å¸‚å ´æ´å¯Ÿ")
       st.info("""
       - ç•¶å‰è¶¨å‹¢åˆ†æ•¸ï¼š78/100
       - å»ºè­°ä¸Šå¸‚æ™‚æ©Ÿï¼š2025 Q2 (Spring)
       - é è¨ˆç«¶çˆ­ç¨‹åº¦ï¼šä¸­ç­‰
       """)

   # è¶¨å‹¢å„€è¡¨æ¿
   with st.expander("ğŸ“ˆ è¶¨å‹¢å„€è¡¨æ¿"):
       trending_keywords = get_top_trends(timeframe="today 3-m")
       for keyword, score in trending_keywords.items():
           st.progress(score/100)
           st.text(f"{keyword}: {score}")
   ```

4. **HF Inference API æ•´åˆ (2 hrs)**
   ```python
   import requests

   HF_API_TOKEN = "hf_xxx"
   API_URL = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0"

   def generate_images_hf(prompt, num_images=4):
       headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}

       images = []
       for i in range(num_images):
           response = requests.post(
               API_URL,
               headers=headers,
               json={"inputs": prompt, "parameters": {"num_inference_steps": 50}}
           )
           image = Image.open(BytesIO(response.content))
           images.append(image)

       return images
   ```

**äº¤ä»˜æˆæœï¼š**
- âœ… `src/obj4_web_app/app.py`
- âœ… `src/obj4_web_app/pages/1_ç”Ÿæˆè¨­è¨ˆ.py`
- âœ… `src/obj4_web_app/pages/2_é æ¸¬èˆ‡è¶¨å‹¢.py`
- âœ… `docs/experiment-logs/day12-streamlit-ui.md`

**å®Œæˆæ¨™æº–ï¼š**
- Streamlit app å¯åœ¨æœ¬åœ°é‹è¡Œ
- UI åŒ…å«å…©å€‹ä¸»è¦é é¢ï¼ˆç”Ÿæˆè¨­è¨ˆã€é æ¸¬èˆ‡è¶¨å‹¢ï¼‰
- HF Inference API æ•´åˆæˆåŠŸ

---

### Day 11: å®Œæ•´ç³»çµ±æ•´åˆæ¸¬è©¦

**ç›®æ¨™ï¼š** ç«¯åˆ°ç«¯æ¸¬è©¦æ‰€æœ‰åŠŸèƒ½

**ä»»å‹™ï¼š**
1. **æœ¬åœ° LSTM é æ¸¬æ¸¬è©¦ (2 hrs)**
   - ç¢ºèª Streamlit å¯æ­£ç¢ºè¼‰å…¥ LSTM æ¨¡å‹
   - æ¸¬è©¦é æ¸¬åŠŸèƒ½ï¼ˆè¼¸å…¥ä¸åŒå­£ç¯€å’Œè¶¨å‹¢ï¼‰
   - é©—è­‰é æ¸¬çµæœåˆç†æ€§

2. **Midjourney API ç”Ÿæˆæ¸¬è©¦ (2 hrs)**
   - æ¸¬è©¦ TTAPI Midjourney API ç©©å®šæ€§
   - é©—è­‰ cref åƒæ•¸è§’è‰²ä¸€è‡´æ€§
   - ç¢ºèªç”Ÿæˆçš„ 4 å¼µåœ–ç‰‡è³ªé‡

3. **å®Œæ•´æµç¨‹æ¸¬è©¦ (3 hrs)**
   ```python
   # æ¸¬è©¦æ¡ˆä¾‹
   test_case_1 = {
       "keywords": ["æ˜¥ç¯€", "ç´…è‰²", "å–œæ…¶"],
       "season": "Spring",
       "expected_sales_range": (1200, 1800)
   }

   # åŸ·è¡Œæµç¨‹
   # 1. åˆ†æè¶¨å‹¢ â†’ 2. ç”Ÿæˆ prompt â†’ 3. ç”Ÿæˆåœ–ç‰‡ â†’ 4. æå– CLIP â†’ 5. é æ¸¬éŠ·é‡
   ```

4. **éŒ¯èª¤è™•ç†èˆ‡å„ªåŒ– (2 hrs)**
   - è™•ç† API timeout
   - è™•ç†ç„¡æ•ˆè¼¸å…¥
   - æ·»åŠ  loading å‹•ç•«
   - å„ªåŒ–é é¢è¼‰å…¥é€Ÿåº¦

**äº¤ä»˜æˆæœï¼š**
- âœ… å®Œæ•´æ¸¬è©¦å ±å‘Šï¼ˆåŒ…å« 3 å€‹æ¸¬è©¦æ¡ˆä¾‹ï¼‰
- âœ… éŒ¯èª¤è™•ç†ç¨‹å¼ç¢¼æ›´æ–°
- âœ… `docs/experiment-logs/day13-integration-testing.md`

**å®Œæˆæ¨™æº–ï¼š**
- 3 å€‹æ¸¬è©¦æ¡ˆä¾‹å…¨éƒ¨é€šé
- ç„¡é˜»å¡æ€§éŒ¯èª¤
- ç”¨æˆ¶é«”é©—æµæš¢

---

### Day 12: å„ªåŒ–èˆ‡ Demo æº–å‚™

**ç›®æ¨™ï¼š** æœ€çµ‚å„ªåŒ–ä¸¦æº–å‚™ Demo å½±ç‰‡

**ä»»å‹™ï¼š**
1. **UI/UX å„ªåŒ– (2 hrs)**
   - æ·»åŠ  ToyzeroPlus å“ç‰Œå…ƒç´ ï¼ˆlogo, é…è‰²ï¼‰
   - æ”¹å–„æ’ç‰ˆå’Œè¦–è¦ºå±¤æ¬¡
   - æ·»åŠ èªªæ˜æ–‡å­—å’Œå·¥å…·æç¤º

2. **æ•ˆèƒ½å„ªåŒ– (2 hrs)**
   - å¿«å– LSTM æ¨¡å‹è¼‰å…¥ï¼ˆ`@st.cache_resource`ï¼‰
   - å¿«å– Google Trends æŸ¥è©¢ï¼ˆ`@st.cache_data`ï¼‰
   - å£“ç¸®ç”Ÿæˆåœ–ç‰‡å¤§å°

3. **Demo è…³æœ¬æ’°å¯« (2 hrs)**
   ```markdown
   ## Demo å½±ç‰‡è…³æœ¬ï¼ˆ5 åˆ†é˜ï¼‰

   ### ç¬¬ 1 å¹•: å°ˆæ¡ˆä»‹ç´¹ (30 ç§’)
   - å•é¡Œé™³è¿°ï¼šToyzeroPlus é¢è‡¨çš„æŒ‘æˆ°
   - è§£æ±ºæ–¹æ¡ˆï¼šAI é©…å‹•çš„è§’è‰²è¨­è¨ˆèˆ‡éœ€æ±‚é æ¸¬ç³»çµ±

   ### ç¬¬ 2 å¹•: åŠŸèƒ½å±•ç¤º (3 åˆ†é˜)
   - å ´æ™¯ 1: åˆ†æ Google Trendsï¼Œç”Ÿæˆæ˜¥ç¯€ä¸»é¡Œè¨­è¨ˆ (1 min)
   - å ´æ™¯ 2: æŸ¥çœ‹ 4 å€‹è¨­è¨ˆè®ŠåŒ–ï¼Œé¸æ“‡æœ€ä½³è¨­è¨ˆ (1 min)
   - å ´æ™¯ 3: é æ¸¬æ˜¥å­£éŠ·é‡ï¼ŒæŸ¥çœ‹å¸‚å ´æ´å¯Ÿ (1 min)

   ### ç¬¬ 3 å¹•: æŠ€è¡“äº®é» (1 åˆ†é˜)
   - Hybrid LSTM æ¶æ§‹
   - Midjourney API cref è§’è‰²ä¸€è‡´æ€§
   - å®Œæ•´é–‰ç’°ç³»çµ±

   ### ç¬¬ 4 å¹•: çµè«–èˆ‡æœªä¾†å±•æœ› (30 ç§’)
   - å°ˆæ¡ˆæˆæœ
   - Future Work æ–¹å‘
   ```

4. **æ–‡æª”æ•´ç† (3 hrs)**
   - æ•´ç†æ‰€æœ‰å¯¦é©—æ—¥èªŒ
   - æ’°å¯« README.md
   - æº–å‚™ FYP å ±å‘Šåˆç¨¿å¤§ç¶±

**äº¤ä»˜æˆæœï¼š**
- âœ… å„ªåŒ–å¾Œçš„ Streamlit app
- âœ… Demo è…³æœ¬ `docs/demo-script.md`
- âœ… `README.md`
- âœ… **Milestone M4 é”æˆ**

**å®Œæˆæ¨™æº–ï¼š**
- Web app å¯ç©©å®šé‹è¡Œï¼Œç„¡æ˜é¡¯ bug
- Demo è…³æœ¬æ’°å¯«å®Œç•¢ï¼Œæ™‚é•·ç´„ 5 åˆ†é˜
- æ–‡æª”æ•´ç†å®Œæˆï¼Œçµæ§‹æ¸…æ™°

---

## ğŸ§ª Testing & Documentation (Day 13-15)

### Day 13: ç«¯åˆ°ç«¯æ¸¬è©¦èˆ‡ Demo éŒ„è£½

**ç›®æ¨™ï¼š** å®Œæˆæœ€çµ‚æ¸¬è©¦ä¸¦éŒ„è£½ Demo å½±ç‰‡

**ä»»å‹™ï¼š**
1. **ç«¯åˆ°ç«¯æ¸¬è©¦ï¼ˆ3 å€‹å®Œæ•´å ´æ™¯ï¼‰(3 hrs)**
   - **å ´æ™¯ A: æ˜¥ç¯€ä¸»é¡Œè§’è‰²è¨­è¨ˆ**
     - è¼¸å…¥ï¼šæ˜¥ç¯€ã€ç´…è‰²ã€å–œæ…¶
     - é æœŸï¼šç”Ÿæˆ 4 å¼µç´…è‰²ä¸»é¡Œè¨­è¨ˆï¼Œé æ¸¬éŠ·é‡ 1400-1600

   - **å ´æ™¯ B: è¬è–ç¯€ä¸»é¡Œè§’è‰²è¨­è¨ˆ**
     - è¼¸å…¥ï¼šè¬è–ç¯€ã€å—ç“œã€ææ€ª
     - é æœŸï¼šç”Ÿæˆ 4 å¼µæ©˜é»‘é…è‰²è¨­è¨ˆï¼Œé æ¸¬éŠ·é‡ 1000-1300

   - **å ´æ™¯ C: è–èª•ç¯€ä¸»é¡Œè§’è‰²è¨­è¨ˆ**
     - è¼¸å…¥ï¼šè–èª•ç¯€ã€é›ªäººã€æº«é¦¨
     - é æœŸï¼šç”Ÿæˆ 4 å¼µå†¬å­£ä¸»é¡Œè¨­è¨ˆï¼Œé æ¸¬éŠ·é‡ 1600-1900

2. **éŒ„è£½ Demo å½±ç‰‡ (3 hrs)**
   - ä½¿ç”¨ OBS Studio æˆ– QuickTime éŒ„è£½è¢å¹•
   - æŒ‰ç…§ Day 12 çš„è…³æœ¬é€²è¡ŒéŒ„è£½
   - æ·»åŠ æ—ç™½è§£èªªï¼ˆä¸­æ–‡æˆ–è‹±æ–‡ï¼‰
   - å¾ŒæœŸå‰ªè¼¯ï¼ˆæ·»åŠ å­—å¹•ã€è½‰å ´ï¼‰

3. **å½±ç‰‡å“è³ªæª¢æŸ¥ (1 hr)**
   - ç¢ºèªéŸ³è¨Šæ¸…æ™°
   - ç¢ºèªç•«é¢æµæš¢ï¼ˆ60 fpsï¼‰
   - ç¢ºèªæ™‚é•·æ§åˆ¶åœ¨ 5-6 åˆ†é˜

4. **æ¸¬è©¦å ±å‘Šæ’°å¯« (2 hrs)**
   - è¨˜éŒ„ 3 å€‹å ´æ™¯çš„æ¸¬è©¦çµæœ
   - æˆªåœ–ä¿å­˜æ¸¬è©¦éç¨‹
   - åˆ†ææˆåŠŸèˆ‡å¤±æ•—æ¡ˆä¾‹

**äº¤ä»˜æˆæœï¼š**
- âœ… `demo-video.mp4` (5-6 åˆ†é˜)
- âœ… `docs/testing/end-to-end-test-report.md`
- âœ… `docs/testing/test-screenshots/` (å ´æ™¯æˆªåœ–)

**å®Œæˆæ¨™æº–ï¼š**
- 3 å€‹æ¸¬è©¦å ´æ™¯å…¨éƒ¨é€šé
- Demo å½±ç‰‡éŒ„è£½å®Œæˆï¼Œè³ªé‡è‰¯å¥½
- æ¸¬è©¦å ±å‘Šè©³ç´°è¨˜éŒ„æ‰€æœ‰çµæœ

---

### Day 14: FYP å ±å‘Šæ’°å¯«

**ç›®æ¨™ï¼š** æ’°å¯« Final Year Project å ±å‘Šåˆç¨¿

**ä»»å‹™ï¼š**
1. **å ±å‘Šçµæ§‹å»ºç«‹ (1 hr)**
   ```markdown
   # FYP Report Structure

   1. Abstract (æ‘˜è¦)
   2. Introduction (å¼•è¨€)
      - Background
      - Problem Statement
      - Objectives
   3. Literature Review (æ–‡ç»å›é¡§)
      - NLP for Prompt Generation
      - Midjourney API for Commercial Design
      - LSTM for Time-Series Forecasting
   4. Methodology (æ–¹æ³•è«–)
      - System Architecture
      - Objective 1: NLP Pipeline
      - Objective 2: Midjourney API Integration
      - Objective 3: Hybrid LSTM
      - Objective 4: Web Integration
   5. Implementation (å¯¦ä½œç´°ç¯€)
      - Technologies Used
      - Data Collection & Simulation
      - Model Training
   6. Results & Evaluation (çµæœèˆ‡è©•ä¼°)
      - Midjourney cref Consistency Analysis
      - LSTM Performance Metrics
      - Feature Importance Analysis
      - System Testing
   7. Discussion (è¨è«–)
      - Achievements
      - Limitations
      - Lessons Learned
   8. Conclusion & Future Work (çµè«–èˆ‡æœªä¾†å·¥ä½œ)
   9. References (åƒè€ƒæ–‡ç»)
   10. Appendices (é™„éŒ„)
   ```

2. **æ ¸å¿ƒç« ç¯€æ’°å¯« (6 hrs)**
   - **Introduction (1 hr):** èƒŒæ™¯ã€å•é¡Œé™³è¿°ã€ç›®æ¨™
   - **Methodology (2 hrs):** ç³»çµ±æ¶æ§‹åœ–ã€å„ Objective æ–¹æ³•èªªæ˜
   - **Implementation (1.5 hrs):** æŠ€è¡“å †ç–Šã€æ•¸æ“šè™•ç†ã€æ¨¡å‹è¨“ç·´ç´°ç¯€
   - **Results (1.5 hrs):** å¯¦é©—çµæœã€åœ–è¡¨ã€æ¯”è¼ƒåˆ†æ

3. **åœ–è¡¨èˆ‡è¡¨æ ¼è£½ä½œ (2 hrs)**
   - ç³»çµ±æ¶æ§‹åœ–ï¼ˆç”¨ draw.io æˆ– Figmaï¼‰
   - LoRA rank æ¯”è¼ƒè¡¨
   - LSTM è¨“ç·´æ›²ç·šåœ–
   - Feature importance æŸ±ç‹€åœ–
   - éŠ·é‡é æ¸¬å°æ¯”åœ–

**äº¤ä»˜æˆæœï¼š**
- âœ… `docs/final-report/fyp-report-draft.md` (åˆç¨¿)
- âœ… `docs/final-report/figures/` (æ‰€æœ‰åœ–è¡¨)
- âœ… `docs/final-report/tables/` (æ‰€æœ‰è¡¨æ ¼)

**å®Œæˆæ¨™æº–ï¼š**
- å ±å‘Šåˆç¨¿å®Œæˆï¼ˆç´„ 8000-10000 å­—ï¼‰
- åŒ…å«è‡³å°‘ 8 å¼µåœ–è¡¨
- æ‰€æœ‰ 4 å€‹ Objectives éƒ½æœ‰è©³ç´°èªªæ˜

---

### Day 15: æœ€çµ‚æª¢æŸ¥èˆ‡æº–å‚™æ¼”ç¤º

**ç›®æ¨™ï¼š** æœ€çµ‚æª¢æŸ¥æ‰€æœ‰äº¤ä»˜æˆæœ

**ä»»å‹™ï¼š**
1. **ç¨‹å¼ç¢¼æª¢æŸ¥ (2 hrs)**
   - ç¢ºèªæ‰€æœ‰ç¨‹å¼ç¢¼æœ‰é©ç•¶è¨»é‡‹
   - æª¢æŸ¥ç¨‹å¼ç¢¼é¢¨æ ¼ä¸€è‡´æ€§
   - ç§»é™¤ debug ç¨‹å¼ç¢¼å’Œæ¸¬è©¦æª”æ¡ˆ

2. **æ–‡æª”æª¢æŸ¥ (2 hrs)**
   - æª¢æŸ¥æ‰€æœ‰ Markdown æ–‡ä»¶æ ¼å¼
   - ç¢ºèªæ‰€æœ‰è¶…é€£çµæœ‰æ•ˆ
   - æ›´æ–° README.mdï¼ˆåŒ…å«å®‰è£å’Œä½¿ç”¨èªªæ˜ï¼‰

3. **Git æ•´ç†èˆ‡æäº¤ (2 hrs)**
   ```bash
   # æª¢æŸ¥æ‰€æœ‰æ›´æ”¹
   git status

   # æ·»åŠ  .gitignore
   echo "*.pyc\n__pycache__/\n.env\nmodels/*.pth\ndata/generated_designs/" > .gitignore

   # æäº¤æœ€çµ‚ç‰ˆæœ¬
   git add .
   git commit -m "feat: complete FYP implementation with all 4 objectives"
   git tag v1.0.0
   ```

4. **æ¼”ç¤ºæº–å‚™ (3 hrs)**
   - æº–å‚™ PowerPoint ç°¡å ±ï¼ˆ10-15 å¼µï¼‰
   - ç·´ç¿’æ¼”ç¤ºæµç¨‹ï¼ˆ5 åˆ†é˜ä»‹ç´¹ + 5 åˆ†é˜ Demo + 5 åˆ†é˜ Q&Aï¼‰
   - æº–å‚™ Q&A å¯èƒ½å•é¡Œçš„ç­”æ¡ˆ

**äº¤ä»˜æˆæœï¼š**
- âœ… ä¹¾æ·¨çš„ Git repository
- âœ… `docs/presentation.pptx` (æ¼”ç¤ºç°¡å ±)
- âœ… æ‰€æœ‰æ–‡æª”æª¢æŸ¥å®Œæˆ
- âœ… **Milestone M5 é”æˆ**

**å®Œæˆæ¨™æº–ï¼š**
- ç¨‹å¼ç¢¼æ•´æ½”ï¼Œç„¡å¤šé¤˜æª”æ¡ˆ
- Git æäº¤è¨˜éŒ„æ¸…æ™°
- æ¼”ç¤ºç°¡å ±æº–å‚™å®Œç•¢
- æº–å‚™å¥½å›ç­”å¸¸è¦‹å•é¡Œ

---

## ğŸ†˜ Day 16-18: Buffer Days (ç·©è¡æ—¥)

### ç”¨é€”
- è™•ç†æ„å¤–å»¶èª¤
- ä¿®å¾©æ¸¬è©¦ä¸­ç™¼ç¾çš„ bug
- æ”¹å–„æ–‡æª”å“è³ª
- é¡å¤–ç·´ç¿’æ¼”ç¤º

### å¯é¸ä»»å‹™
- å„ªåŒ– Demo å½±ç‰‡ï¼ˆé‡æ–°éŒ„è£½æˆ–æ”¹å–„å‰ªè¼¯ï¼‰
- æ”¹å–„ FYP å ±å‘Šï¼ˆå¢åŠ ç´°ç¯€ã€æ”¹å–„åœ–è¡¨ï¼‰
- æ·»åŠ é¡å¤–åŠŸèƒ½ï¼ˆå¦‚æœæ™‚é–“å……è¶³ï¼‰
- æº–å‚™å‚™æ¡ˆ Demoï¼ˆé›¢ç·šç‰ˆæœ¬ï¼‰

---

## ğŸ¯ é—œéµé¢¨éšªèˆ‡ç·©è§£ç­–ç•¥

### æŠ€è¡“é¢¨éšª

| é¢¨éšª | åš´é‡æ€§ | æ©Ÿç‡ | ç·©è§£ç­–ç•¥ |
|------|--------|------|----------|
| **GPT_API_free ä¸ç©©å®š** | é«˜ | ä¸­ | æº–å‚™ Mistral-7B (HF) ä½œå‚™æ¡ˆ |
| **TTAPI Midjourney API ä¸ç©©å®š** | é«˜ | ä¸­ | æå‰è³¼è²· quota ä¸¦æ¸¬è©¦ï¼Œæº–å‚™ DALL-E 3 æˆ– Flux ä½œå‚™æ¡ˆ |
| **Midjourney cref ä¸€è‡´æ€§ä¸ä½³** | ä¸­ | ä¸­ | æ¸¬è©¦å¤šå¼µåƒè€ƒåœ–ç‰‡ï¼Œé¸æ“‡æœ€ä½³æ•ˆæœï¼›é™ç´šæ–¹æ¡ˆç‚ºæ¥å—è¼ƒä½ä¸€è‡´æ€§ |
| **LSTM é æ¸¬ä¸æº–ç¢º** | é«˜ | ä¸­ | èª¿æ•´æ¨¡æ“¬è¦å‰‡ï¼Œå¢åŠ æ•¸æ“šé‡ |
| **TTAPI quota å®šåƒ¹è®Šå‹•** | ä¸­ | ä½ | æå‰è³¼è²·ä¸¦é–å®šå®šåƒ¹ï¼Œè¨˜éŒ„ç¢ºåˆ‡æˆæœ¬ |

### æ™‚é–“é¢¨éšª

| é¢¨éšª | åš´é‡æ€§ | æ©Ÿç‡ | ç·©è§£ç­–ç•¥ |
|------|--------|------|----------|
| **å–®å€‹ Objective è¶…æ™‚** | é«˜ | ä¸­ | ä½¿ç”¨ Buffer Daysï¼Œç°¡åŒ–åŠŸèƒ½ |
| **Pikachu åƒè€ƒåœ–ç‰‡é¸æ“‡å›°é›£** | ä½ | ä½ | æº–å‚™ 3-5 å¼µå€™é¸åœ–ç‰‡ï¼Œå¿«é€Ÿæ¸¬è©¦é¸æ“‡æœ€ä½³ |
| **Demo éŒ„è£½å¤±æ•—** | ä¸­ | ä½ | é ç•™ Day 16-18 é‡æ–°éŒ„è£½ |
| **æ–‡æª”æ’°å¯«ä¸è¶³** | ä½ | ä½ | æ¯æ—¥å¯«å¯¦é©—æ—¥èªŒï¼Œæ¸›å°‘æœ€å¾Œè² æ“” |

### è³‡æºé¢¨éšª

| é¢¨éšª | åš´é‡æ€§ | æ©Ÿç‡ | ç·©è§£ç­–ç•¥ |
|------|--------|------|----------|
| **å…è²» API é™åˆ¶** | ä¸­ | ä¸­ | åˆ†æ•£ä½¿ç”¨æ™‚é–“ï¼Œé¿å…é›†ä¸­å‘¼å« |
| **å„²å­˜ç©ºé–“ä¸è¶³** | ä½ | ä½ | å®šæœŸæ¸…ç†è‡¨æ™‚æª”æ¡ˆ |
| **ç¶²è·¯é€£ç·šä¸­æ–·** | ä¸­ | ä½ | æœ¬åœ°ä¿å­˜æ‰€æœ‰ç¨‹å¼ç¢¼å’Œæ¨¡å‹ |

---

## ğŸ“Š æ¯æ—¥æª¢æŸ¥æ¸…å–® (Daily Checklist)

æ¯æ—¥çµæŸå‰å®Œæˆä»¥ä¸‹æª¢æŸ¥ï¼š

- [ ] **ç¨‹å¼ç¢¼æäº¤ï¼š** ç•¶æ—¥æ‰€æœ‰æ›´æ”¹å·² commit åˆ° Git
- [ ] **å¯¦é©—è¨˜éŒ„ï¼š** æ’°å¯«ç•¶æ—¥å¯¦é©—æ—¥èªŒï¼ˆ`docs/experiment-logs/dayX-xxx.md`ï¼‰
- [ ] **æ¸¬è©¦é©—è­‰ï¼š** ç•¶æ—¥å¯¦ä½œçš„åŠŸèƒ½å·²é€šéåŸºæœ¬æ¸¬è©¦
- [ ] **æª”æ¡ˆå‚™ä»½ï¼š** é‡è¦æª”æ¡ˆå·²å‚™ä»½ï¼ˆæ¨¡å‹æ¬Šé‡ã€æ•¸æ“šé›†ï¼‰
- [ ] **é€²åº¦æ›´æ–°ï¼š** æ›´æ–°å¯¦æ–½è·¯ç·šåœ–çš„å®Œæˆç‹€æ…‹ï¼ˆâœ… / âš ï¸ / âŒï¼‰
- [ ] **é¢¨éšªè©•ä¼°ï¼š** è­˜åˆ¥ä¸¦è¨˜éŒ„ç•¶æ—¥é‡åˆ°çš„é¢¨éšªæˆ–é˜»ç¤™

---

## ğŸ“ FYP å ±å‘Šæ–‡æª”çµæ§‹

### å¿…é ˆåŒ…å«çš„ç« ç¯€

1. **Abstract (200-300 å­—)**
   - å•é¡Œé™³è¿°
   - è§£æ±ºæ–¹æ¡ˆæ¦‚è¿°
   - é—œéµçµæœ
   - çµè«–

2. **Introduction (1500-2000 å­—)**
   - Background: ToyzeroPlus æ¥­å‹™èƒŒæ™¯
   - Problem Statement: è§’è‰²è¨­è¨ˆèˆ‡éœ€æ±‚é æ¸¬æŒ‘æˆ°
   - Objectives: 4 å€‹ä¸»è¦ç›®æ¨™
   - Report Structure: å ±å‘Šç« ç¯€æ¦‚è¿°

3. **Literature Review (2000-2500 å­—)**
   - NLP for Text Generation (TF-IDF, LLM)
   - Generative AI (Midjourney, Commercial APIs)
   - Time-Series Forecasting (LSTM, GRU)
   - Related Work: é¡ä¼¼ç³»çµ±æ¡ˆä¾‹

4. **Methodology (3000-3500 å­—)**
   - System Architecture Overview
   - Objective 1: NLP Prompt Generation Pipeline
   - Objective 2: Midjourney API Integration Strategy
   - Objective 3: Hybrid LSTM Architecture
   - Objective 4: Web Application Design

5. **Implementation (2000-2500 å­—)**
   - Technologies & Tools
   - Data Collection & Simulation
   - Model Training Details
   - Integration Approach

6. **Results & Evaluation (2000-2500 å­—)**
   - Midjourney cref Consistency Analysis
   - LSTM Performance Metrics (MAE, RMSE, RÂ²)
   - Feature Importance Analysis
   - System Testing Results

7. **Discussion (1000-1500 å­—)**
   - Achievements & Contributions
   - Limitations & Constraints
   - Challenges Encountered
   - Lessons Learned

8. **Conclusion & Future Work (800-1000 å­—)**
   - Project Summary
   - Future Improvements (4 categories from brainstorming)
   - Final Thoughts

9. **References (è‡³å°‘ 20 ç¯‡)**
   - Academic papers
   - Technical documentation
   - Open-source projects

10. **Appendices**
    - Source Code Listings
    - Experiment Data Tables
    - Additional Figures

### é è¨ˆç¸½å­—æ•¸ï¼š12000-15000 å­—

---

## ğŸš€ å¿«é€Ÿå•Ÿå‹•æŒ‡ä»¤

### å‰æœŸæº–å‚™
```bash
# 1. Clone repository
git clone <repo-url>
cd FYP-RoleMarket

# 2. å»ºç«‹è™›æ“¬ç’°å¢ƒ
python -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# 3. å®‰è£ä¾è³´
pip install -r requirements.txt

# 4. è¨­å®šç’°å¢ƒè®Šæ•¸
cp .env.example .env
# ç·¨è¼¯ .envï¼Œå¡«å…¥ API keys
```

### åŸ·è¡Œå„ Objective
```bash
# Objective 1: NLP Prompt ç”Ÿæˆ
python src/obj1_nlp_prompt/pipeline.py

# Objective 2: Midjourney API æ‰¹é‡ç”Ÿæˆ
python src/obj2_midjourney_api/batch_generator.py

# Objective 3: LSTM è¨“ç·´
python src/obj3_lstm_forecast/train.py

# Objective 4: å•Ÿå‹• Web App
streamlit run src/obj4_web_app/app.py
```

---

## ğŸ“ æ”¯æ´è³‡æº

### æŠ€è¡“æ–‡æª”
- [pytrends Documentation](https://pypi.org/project/pytrends/)
- [TTAPI Midjourney API Docs](https://ttapi.io/docs/apiReference/midjourney)
- [Midjourney Character Reference Guide](https://docs.midjourney.com/docs/character-reference)
- [LSTM Tutorial](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [Streamlit Documentation](https://docs.streamlit.io/)

### ç¤¾ç¾¤æ”¯æ´
- Hugging Face Forums
- TTAPI Discord/Support
- ToyzeroPlus å…§éƒ¨ Slackï¼ˆå¦‚æœ‰ï¼‰

### ç·Šæ€¥è¯çµ¡
- FYP Supervisor: [è¯çµ¡æ–¹å¼]
- ToyzeroPlus è¯çµ¡äºº: [è¯çµ¡æ–¹å¼]

---

## âœ… æœ€çµ‚äº¤ä»˜æ¸…å–® (Final Deliverables)

### ç¨‹å¼ç¢¼
- [x] å®Œæ•´åŸå§‹ç¢¼ï¼ˆ4 å€‹ Objectivesï¼‰
- [x] Requirements.txt
- [x] README.md
- [x] .gitignore

### æ¨¡å‹èˆ‡æ•¸æ“š
- [x] Midjourney ç”Ÿæˆçš„ 28 å¼µè¨­è¨ˆåœ–ç‰‡
- [x] LSTM æ¨¡å‹æ¬Šé‡
- [x] æ¨¡æ“¬éŠ·å”®æ•¸æ“šï¼ˆ60 å€‹æ•¸æ“šé»ï¼‰
- [x] CLIP embeddings è³‡æ–™åº«

### æ–‡æª”
- [x] Brainstorming Session Results
- [x] Implementation Roadmap (æ­¤æ–‡ä»¶)
- [x] æ‰€æœ‰å¯¦é©—æ—¥èªŒï¼ˆDay 1-15ï¼‰
- [x] FYP å ±å‘Šåˆç¨¿
- [x] Market Insights å ±å‘Š

### æ¼”ç¤ºææ–™
- [x] Demo å½±ç‰‡ï¼ˆ5-6 åˆ†é˜ï¼‰
- [x] æ¼”ç¤ºç°¡å ± (PPT)
- [x] æ¸¬è©¦æˆªåœ–

### Web App
- [x] å¯é‹è¡Œçš„ Streamlit æ‡‰ç”¨
- [x] ä½¿ç”¨èªªæ˜æ–‡ä»¶

---

## ğŸ‰ æˆåŠŸæ¨™æº–

### æŠ€è¡“æ¨™æº–
- âœ… æ‰€æœ‰ 4 å€‹ Objectives å®Œæˆä¸¦å¯é‹è¡Œ
- âœ… LSTM æ¸¬è©¦é›† RÂ² > 0.7
- âœ… Midjourney cref è§’è‰²ä¸€è‡´æ€§ > 0.75 (CLIP similarity)
- âœ… Web App ç„¡é˜»å¡æ€§éŒ¯èª¤

### å­¸è¡“æ¨™æº–
- âœ… FYP å ±å‘Š > 12000 å­—
- âœ… åŒ…å«å¯¦é©—æ¯”è¼ƒï¼ˆMidjourney cref æ¸¬è©¦, LSTM vs GRUï¼‰
- âœ… æœ‰æ¸…æ™°çš„ç³»çµ±æ¶æ§‹åœ–
- âœ… åƒè€ƒæ–‡ç» > 20 ç¯‡

### æ¼”ç¤ºæ¨™æº–
- âœ… Demo å½±ç‰‡ 5-6 åˆ†é˜ï¼Œè³ªé‡è‰¯å¥½
- âœ… å¯å®Œæ•´å±•ç¤º 3 å€‹å ´æ™¯
- âœ… æº–å‚™å¥½å›ç­”æŠ€è¡“å•é¡Œ

---

**æœ€å¾Œæ›´æ–°ï¼š** 2025-10-29
**å°ˆæ¡ˆé–‹å§‹æ—¥æœŸï¼š** 2025-01-20
**Objective 3 å®Œæˆæ—¥æœŸï¼š** 2025-10-29

**å·²å®Œæˆ Objectivesï¼š** Obj 1 âœ…, Obj 2 âœ…, Obj 3 âœ…
**ä¸‹ä¸€æ­¥ï¼š** Objective 4 (Web Integration)

**ç¥ä½ å°ˆæ¡ˆé †åˆ©ï¼åŠ æ²¹ï¼ğŸ’ª**
