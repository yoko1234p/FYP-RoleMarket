"""
é©—è­‰ V2 ç”Ÿæˆåœ–ç‰‡çš„è§’è‰²ä¸€è‡´æ€§

ä½¿ç”¨ CLIP æ¨¡å‹é©—è­‰å„ªåŒ–å¾Œçš„å ´æ™¯åœ–ç‰‡ï¼Œç›®æ¨™ï¼šç›¸ä¼¼åº¦ >= 0.8

Author: Product Manager (John)
Date: 2025-10-27
Version: 2.0
"""

import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent))

import json
import logging
from obj2_midjourney_api.clip_validator import CLIPValidator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def validate_v2_images():
    """é©—è­‰ V2 ç”Ÿæˆåœ–ç‰‡çš„è§’è‰²ä¸€è‡´æ€§ã€‚"""
    logger.info(f"\n{'='*80}")
    logger.info("é©—è­‰ V2 ç”Ÿæˆåœ–ç‰‡è§’è‰²ä¸€è‡´æ€§ï¼ˆç›®æ¨™ï¼š>= 0.8ï¼‰")
    logger.info(f"{'='*80}\n")

    # Initialize CLIP validator
    validator = CLIPValidator()

    # åƒè€ƒåœ–ç‰‡
    reference_image = 'data/generated_images/comparison_test/comparison_2_gpt_enhanced.png'

    # V2 å ´æ™¯åœ–ç‰‡
    v2_images = {
        'Halloween V2': 'data/generated_images/scene_variations_v2/lulu_halloween_v2.png',
        'Spring Festival V2': 'data/generated_images/scene_variations_v2/lulu_spring_festival_v2.png',
        'Birthday V2': 'data/generated_images/scene_variations_v2/lulu_birthday_v2.png',
        'Summer V2': 'data/generated_images/scene_variations_v2/lulu_summer_v2.png',
    }

    # é©—è­‰åœ–ç‰‡å­˜åœ¨æ€§
    all_images = [reference_image] + list(v2_images.values())
    missing_images = []
    for img_path in all_images:
        if not Path(img_path).exists():
            missing_images.append(img_path)

    if missing_images:
        logger.error(f"âŒ ä»¥ä¸‹åœ–ç‰‡ä¸å­˜åœ¨ï¼š")
        for img in missing_images:
            logger.error(f"   - {img}")
        return None

    logger.info(f"âœ… æ‰¾åˆ°æ‰€æœ‰åœ–ç‰‡\n")

    # è¨ˆç®—åƒè€ƒåœ–ç‰‡çš„ embedding
    logger.info("è¨ˆç®—åƒè€ƒåœ–ç‰‡ embedding...")
    ref_embedding = validator.compute_embedding(reference_image)
    logger.info(f"  âœ“ Reference (GPT-Enhanced)\n")

    # è¨ˆç®—å„å ´æ™¯åœ–ç‰‡èˆ‡åƒè€ƒåœ–ç‰‡çš„ç›¸ä¼¼åº¦
    logger.info(f"{'â”€'*80}")
    logger.info("è¨ˆç®—èˆ‡åƒè€ƒåœ–ç‰‡çš„ç›¸ä¼¼åº¦...")
    logger.info(f"{'â”€'*80}\n")

    results = {
        'reference_image': reference_image,
        'v2_images': {},
        'statistics': {}
    }

    similarities = []

    for scene_name, scene_path in v2_images.items():
        scene_embedding = validator.compute_embedding(scene_path)
        similarity = validator.compute_similarity(ref_embedding, scene_embedding)

        results['v2_images'][scene_name] = {
            'path': scene_path,
            'similarity': round(similarity, 4)
        }

        similarities.append(similarity)

        # æª¢æŸ¥æ˜¯å¦é”åˆ°ç›®æ¨™ >= 0.8
        if similarity >= 0.80:
            status = "âœ… PASS (>= 0.8)"
            emoji = "ğŸŒŸ"
        elif similarity >= 0.75:
            status = "âœ… PASS (>= 0.75)"
            emoji = "ğŸ‘"
        else:
            status = "âš ï¸ WARN (< 0.75)"
            emoji = "âš ï¸"

        logger.info(f"{emoji} {scene_name:25s}: {similarity:.4f} {status}")

    # çµ±è¨ˆæ•¸æ“š
    avg_similarity = sum(similarities) / len(similarities)
    min_similarity = min(similarities)
    max_similarity = max(similarities)

    passed_08 = sum(1 for s in similarities if s >= 0.80)
    passed_075 = sum(1 for s in similarities if s >= 0.75)

    results['statistics'] = {
        'total_scenes': len(similarities),
        'avg_similarity': round(avg_similarity, 4),
        'min_similarity': round(min_similarity, 4),
        'max_similarity': round(max_similarity, 4),
        'target_threshold': 0.80,
        'core_threshold': 0.75,
        'passed_0.8': passed_08,
        'passed_0.75': passed_075,
        'failed': sum(1 for s in similarities if s < 0.75)
    }

    # è¼¸å‡ºçµ±è¨ˆçµæœ
    logger.info(f"\n{'='*80}")
    logger.info("çµ±è¨ˆçµæœ")
    logger.info(f"{'='*80}\n")

    logger.info(f"ç¸½å ´æ™¯æ•¸é‡: {results['statistics']['total_scenes']}")
    logger.info(f"å¹³å‡ç›¸ä¼¼åº¦: {results['statistics']['avg_similarity']:.4f}")
    logger.info(f"æœ€ä½ç›¸ä¼¼åº¦: {results['statistics']['min_similarity']:.4f}")
    logger.info(f"æœ€é«˜ç›¸ä¼¼åº¦: {results['statistics']['max_similarity']:.4f}")
    logger.info(f"\nç›®æ¨™ Threshold (>= 0.8): {results['statistics']['passed_0.8']}/{results['statistics']['total_scenes']} é€šé")
    logger.info(f"Core Threshold (>= 0.75): {results['statistics']['passed_0.75']}/{results['statistics']['total_scenes']} é€šé")

    # è©•ä¼°æ”¹é€²æ•ˆæœ
    logger.info(f"\n{'â”€'*80}")
    logger.info("æ”¹é€²æ•ˆæœè©•ä¼°")
    logger.info(f"{'â”€'*80}\n")

    # èˆ‡ V1 çµæœæ¯”è¼ƒï¼ˆå¾ä¹‹å‰çš„çµæœï¼‰
    v1_avg = 0.7949  # V1 å¹³å‡ç›¸ä¼¼åº¦ï¼ˆåŒ…æ‹¬å ´æ™¯ä¹‹é–“çš„ç›¸ä¼¼åº¦ï¼‰
    v1_ref_to_scenes = [0.7171, 0.8105, 0.8380, 0.7198]  # V1 ä¸­ GPT-Enhanced åˆ°å„å ´æ™¯çš„ç›¸ä¼¼åº¦
    v1_avg_ref_to_scenes = sum(v1_ref_to_scenes) / len(v1_ref_to_scenes)

    improvement = avg_similarity - v1_avg_ref_to_scenes

    logger.info(f"V1 å¹³å‡ç›¸ä¼¼åº¦ï¼ˆref â†’ scenesï¼‰: {v1_avg_ref_to_scenes:.4f}")
    logger.info(f"V2 å¹³å‡ç›¸ä¼¼åº¦ï¼ˆref â†’ scenesï¼‰: {avg_similarity:.4f}")
    logger.info(f"æ”¹é€²å¹…åº¦: {improvement:+.4f} ({improvement/v1_avg_ref_to_scenes*100:+.2f}%)")

    if avg_similarity >= 0.80:
        consistency_level = "å„ªç§€ (Excellent) - é”åˆ°ç›®æ¨™ï¼"
        emoji = "ğŸŒŸ"
    elif avg_similarity >= 0.75:
        consistency_level = "è‰¯å¥½ (Good) - æ¥è¿‘ç›®æ¨™"
        emoji = "âœ…"
    else:
        consistency_level = "éœ€è¦æ”¹é€² (Needs Improvement)"
        emoji = "âš ï¸"

    results['statistics']['consistency_level'] = consistency_level
    results['statistics']['improvement_vs_v1'] = round(improvement, 4)

    logger.info(f"\n{emoji} è§’è‰²ä¸€è‡´æ€§ç­‰ç´š: {consistency_level}")

    # ä¿å­˜çµæœ
    output_path = Path('data/generated_images/clip_validation_v2_results.json')
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    logger.info(f"\nğŸ’¾ é©—è­‰çµæœå·²å„²å­˜: {output_path}")

    logger.info(f"\n{'='*80}")
    logger.info("é©—è­‰å®Œæˆï¼")
    logger.info(f"{'='*80}\n")

    return results


def main():
    """åŸ·è¡Œé©—è­‰ã€‚"""
    results = validate_v2_images()

    if results:
        logger.info("âœ… V2 è§’è‰²ä¸€è‡´æ€§é©—è­‰å®Œæˆï¼")

        # ç¸½çµå»ºè­°
        avg = results['statistics']['avg_similarity']
        if avg >= 0.80:
            logger.info("\nğŸ‰ æ­å–œï¼å·²é”åˆ°ç›®æ¨™ç›¸ä¼¼åº¦ >= 0.8")
        else:
            logger.info(f"\nğŸ’¡ å»ºè­°ï¼šå¹³å‡ç›¸ä¼¼åº¦ {avg:.4f}ï¼Œè·é›¢ç›®æ¨™ 0.8 é‚„å·® {0.8 - avg:.4f}")
            logger.info("   å¯ä»¥é€²ä¸€æ­¥å„ªåŒ– promptï¼Œæ¸›å°‘é®æ“‹é—œéµç‰¹å¾µçš„æœé£¾")
    else:
        logger.error("âŒ é©—è­‰å¤±æ•—")


if __name__ == '__main__':
    main()
